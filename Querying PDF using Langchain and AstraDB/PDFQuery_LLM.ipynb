{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e558352f-7038-4fa7-bb2c-7efc88d14689",
   "metadata": {},
   "source": [
    "## Querying PDF using Langchain and Astra DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d5d8b9-3256-4b5b-bcee-1b429a03da12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:12.120721Z",
     "start_time": "2024-04-27T20:50:10.636672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (from pyarrow) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa5ddcf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:13.353721Z",
     "start_time": "2024-04-27T20:50:12.120999Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d98af7-d331-48de-a290-4a7007e59304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:14.737786Z",
     "start_time": "2024-04-27T20:50:13.354170Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q cassio datasets langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07e0e32-b0df-4e04-8479-c75c25d0ece1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:16.748361Z",
     "start_time": "2024-04-27T20:50:15.483964Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (from PyPDF2) (4.9.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd456b9-590b-4842-9ba7-0239d31d78dd",
   "metadata": {},
   "source": [
    "### Import the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cff11319-86f8-463a-b39b-ee733e36e69d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:18.890332Z",
     "start_time": "2024-04-27T20:50:18.878578Z"
    }
   },
   "outputs": [],
   "source": [
    "# LangChain components \n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    " \n",
    "import cassio\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0c10d-e077-46ce-a9bc-d5dea231ff53",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e1ccc68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:21.142456Z",
     "start_time": "2024-04-27T20:50:21.133778Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5882ae0f-6edd-43fa-b197-9b6fcf534ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:21.858290Z",
     "start_time": "2024-04-27T20:50:21.851437Z"
    }
   },
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_ID = os.getenv(\"ASTRA_DB_ID\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5456d86-3527-4d11-8a92-5aa1fa8d1fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:23.821266Z",
     "start_time": "2024-04-27T20:50:23.814637Z"
    }
   },
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('Generative_AI.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c22959c-07d6-40a7-a2d5-cab567a9ec3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:25.915405Z",
     "start_time": "2024-04-27T20:50:25.228629Z"
    }
   },
   "outputs": [],
   "source": [
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee116f0-1033-45c6-87eb-4cc5554fbe88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:33.328961Z",
     "start_time": "2024-04-27T20:50:27.616929Z"
    }
   },
   "source": [
    "### Initializing connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7790d39f-3a81-4e7c-991b-2072abb63148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T19:26:16.233494Z",
     "start_time": "2024-04-26T19:26:09.515250Z"
    }
   },
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a1d82-89e1-4a52-9615-bc032a5cd5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:36.511219Z",
     "start_time": "2024-04-27T20:50:36.422028Z"
    }
   },
   "source": [
    "### Create the LangChain embedding and LLM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ce083c-60b0-4573-88af-1f7933a65059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T19:26:24.429864Z",
     "start_time": "2024-04-26T19:26:24.355044Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdfdf7-d21f-4ba1-a0f4-0a08b21f41e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T20:50:45.380775Z",
     "start_time": "2024-04-27T20:50:45.003738Z"
    }
   },
   "source": [
    "### Create your LangChain vector store (backed by Astra DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da470d04-2b92-41c6-968b-967be379f760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T19:26:33.849584Z",
     "start_time": "2024-04-26T19:26:33.379420Z"
    }
   },
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6476cb64-48ff-4cc3-8948-5ece87866f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T19:24:48.157698Z",
     "start_time": "2024-04-26T19:24:48.138272Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "810c61ab-3e96-4170-aef1-130c67965e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:38.811518Z",
     "start_time": "2024-04-26T14:28:38.768926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CATCHWORD\\nGenerative AI\\nStefan Feuerriegel •Jochen Hartmann •Christian Janiesch •\\nPatrick Zschech\\nReceived: 29 April 2023 / Accepted: 7 August 2023 / Published online: 12 September 2023\\n/C211The Author(s) 2023\\nKeywords Generative AI /C1Artiﬁcial intelligence /C1\\nDecision support /C1Content creation /C1Information systems\\n1 Introduction\\nTom Freston is credited with saying ‘‘Innovation is taking\\ntwo things that exist and putting them together in a new\\nway’’. For a long time in history, it has been the prevailingassumption that artistic, creative tasks such as writing\\npoems, creating software, designing fashion, and compos-\\ning songs could only be performed by humans. Thisassumption has changed drastically with recent advances in\\nartiﬁcial intelligence (AI) that can generate new content in',\n",
       " 'ing songs could only be performed by humans. Thisassumption has changed drastically with recent advances in\\nartiﬁcial intelligence (AI) that can generate new content in\\nways that cannot be distinguished anymore from humancraftsmanship.The term generative AI refers to computational tech-\\nniques that are capable of generating seemingly new,\\nmeaningful content such as text, images, or audio fromtraining data. The widespread diffusion of this technology\\nwith examples such as Dall-E 2, GPT-4, and Copilot is\\ncurrently revolutionizing the way we work and communi-cate with each other. Generative AI systems can not only\\nbe used for artistic purposes to create new text mimicking\\nwriters or new images mimicking illustrators, but they canand will assist humans as intelligent question-answering',\n",
       " 'be used for artistic purposes to create new text mimicking\\nwriters or new images mimicking illustrators, but they canand will assist humans as intelligent question-answering\\nsystems. Here, applications include information technology\\n(IT) help desks where generative AI supports transitionalknowledge work tasks and mundane needs such as cooking\\nrecipes and medical advice. Industry reports suggest that\\ngenerative AI could raise global gross domestic product(GDP) by 7% and replace 300 million jobs of knowledge\\nworkers (Goldman Sachs 2023 ). Undoubtedly, this has\\ndrastic implications not only for the Business & Informa-tion Systems Engineering (BISE) community, where we\\nwill face revolutionary opportunities, but also challenges\\nand risks that we need to tackle and manage to steer the',\n",
       " 'will face revolutionary opportunities, but also challenges\\nand risks that we need to tackle and manage to steer the\\ntechnology and its use in a responsible and sustainable\\ndirection.\\nIn this Catchword article, we provide a conceptualiza-\\ntion of generative AI as an entity in socio-technical systems\\nand provide examples of models, systems, and applica-tions. Based on that, we introduce limitations of current\\ngenerative AI and provide an agenda for BISE research.\\nPrevious papers discuss generative AI around speciﬁcmethods such as language models (e.g., Teubner et al.\\n2023 ; Dwivedi et al. 2023 ; Scho ¨bel et al. 2023 ) or speciﬁc\\napplications such as marketing (e.g., Peres et al. 2023 ),\\ninnovation management (Burger et al. 2023 ), scholarly',\n",
       " '2023 ; Dwivedi et al. 2023 ; Scho ¨bel et al. 2023 ) or speciﬁc\\napplications such as marketing (e.g., Peres et al. 2023 ),\\ninnovation management (Burger et al. 2023 ), scholarly\\nresearch (e.g., Susarla et al. 2023 ; Davison et al. 2023 ),\\nand education (e.g., Kasneci et al. 2023 ; Gimpel et al.Accepted after one revision by Susanne Strahringer.\\nS. Feuerriegel ( &)\\nLMU Munich and Munich Center for Machine Learning,\\nGeschwister-Scholl-Platz 1, 80539 Munich, Germanye-mail: feuerriegel@lmu.de\\nJ. Hartmann\\nTechnical University of Munich, TUM School of Management,Arcisstr. 21, 80333 Munich, Germanye-mail: jochen.hartmann@tum.de\\nC. Janiesch\\nTU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund,Germanye-mail: christian.janiesch@tu-dortmund.de\\nP. Zschech',\n",
       " 'C. Janiesch\\nTU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund,Germanye-mail: christian.janiesch@tu-dortmund.de\\nP. Zschech\\nFAU Erlangen-Nu ¨rnberg, Lange Gasse 20, 90403 Nu ¨rnberg,\\nGermanye-mail: patrick.zschech@fau.de\\n123Bus Inf Syst Eng 66(1):111–126 (2024)\\nhttps://doi.org/10.1007/s12599-023-00834-7\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.2023 ). Different from these works, we focus on generative\\nAI in the context of information systems, and, to this end,\\nwe discuss several opportunities and challenges that are\\nunique to the BISE community and make suggestions forimpactful directions for BISE research.\\n2 Conceptualization\\n2.1 Mathematical Principles of Generative AIGenerative AI is primarily based on generative modeling,',\n",
       " '2 Conceptualization\\n2.1 Mathematical Principles of Generative AIGenerative AI is primarily based on generative modeling,\\nwhich has distinctive mathematical differences from dis-\\ncriminative modeling (Ng and Jordan 2001 ) often used in\\ndata-driven decision support. In general, discriminativemodeling tries to separate data points Xinto different\\nclasses Yby learning decision boundaries between them\\n(e.g., in classiﬁcation tasks with Y2f0;1g). In contrast to\\nthat, generative modeling aims to infer some actual data\\ndistribution. Examples can be the joint probability distri-\\nbution P(X,Y) of both the inputs and the outputs or P(Y),\\nbut where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to',\n",
       " 'bution P(X,Y) of both the inputs and the outputs or P(Y),\\nbut where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to\\nproduce new synthetic samples (e.g., generate new obser-vation-target-pairs ( X,Y) or new observations Xgiven a\\ntarget value Y) (Bishop 2006 ).\\nBuilding upon the above, a generative AI model refers to\\ngenerative modeling that is instantiated with a machine\\nlearning architecture (e.g., a deep neural network) and,\\ntherefore, can create new data samples based on learnedpatterns.\\n1Further, a generative AI system encompasses the\\nentire infrastructure, including the model, data processing,\\nand user interface components. The model serves as thecore component of the system, which facilitates interaction',\n",
       " 'entire infrastructure, including the model, data processing,\\nand user interface components. The model serves as thecore component of the system, which facilitates interaction\\nand application within a broader context. Lastly, generative\\nAI applications refer to the practical use cases and imple-\\nmentations of these systems, such as search engine opti-\\nmization (SEO) content generation or code generation that\\nsolve real-world problems and drive innovation acrossvarious domains. Figure 1shows a systematization of\\ngenerative AI across selected data modalities (e.g., text,\\nimage, and audio) and the model-, system-, and application-level perspectives, which we detail in the following section.Note that the modalities in Fig. 1are neither complete',\n",
       " 'image, and audio) and the model-, system-, and application-level perspectives, which we detail in the following section.Note that the modalities in Fig. 1are neither complete\\nnor entirely distinctive and can be detailed further. In\\naddition, many unique use cases such as, for example,\\nmodeling functional properties of proteins (Unsal et al.2022 ) can be represented in another modality such as text.\\n2.2 A Model-, System-, and Application-Level View\\nof Generative AI\\n2.2.1 Model-Level ViewA generative AI model is a type of machine learning\\narchitecture that uses AI algorithms to create novel data\\ninstances, drawing upon the patterns and relationships\\nobserved in the training data. A generative AI model is ofcritically central yet incomplete nature, as it requires fur-',\n",
       " 'instances, drawing upon the patterns and relationships\\nobserved in the training data. A generative AI model is ofcritically central yet incomplete nature, as it requires fur-\\nther ﬁne-tuning to speciﬁc tasks through systems and\\napplications.\\nDeep neural networks are particularly well suited for the\\npurpose of data generation, especially as deep neural net-\\nworks can be designed using different architectures tomodel different data types (Janiesch et al. 2021 ; Kraus\\net al. 2020 ), for example, sequential data such as human\\nlanguage or spatial data such as images. Table 1presents\\nan overview of the underlying concepts and model archi-\\ntectures that are common in the context of generative AI,',\n",
       " 'language or spatial data such as images. Table 1presents\\nan overview of the underlying concepts and model archi-\\ntectures that are common in the context of generative AI,\\nsuch as diffusion probabilistic models for text-to-imagegeneration or the transformer architecture and (large) lan-\\nguage models (LLMs) for text generation. GPT (short for\\ngenerative pre-trained transformer), for example, repre-sents a popular family of LLMs, used for text generation,\\nfor instance, in the conversational agent ChatGPT.\\nLarge generative AI models that can model output in\\nand across speciﬁc domains or speciﬁc data types in a\\ncomprehensive and versatile manner are oftentimes also\\ncalled foundation models (Bommasani et al. 2021 ). Due to\\ntheir size, they exhibit two key properties: emergence ,',\n",
       " 'comprehensive and versatile manner are oftentimes also\\ncalled foundation models (Bommasani et al. 2021 ). Due to\\ntheir size, they exhibit two key properties: emergence ,\\nmeaning the behavior is oftentimes implicitly induced\\nrather than explicitly constructed (e.g., GPT models cancreate calendar entries in the .ical format even though such\\nmodels were not explicitly trained to do so), and homog-\\nenization , where a wide range of systems and applications\\ncan now be powered by a single, consolidated model (e.g.,\\nCopilot can generate source code across a wide range of\\nprogramming languages).\\nFigure 1presents an overview of generative AI models\\nalong different, selected data modalities, which are pre-',\n",
       " 'Copilot can generate source code across a wide range of\\nprogramming languages).\\nFigure 1presents an overview of generative AI models\\nalong different, selected data modalities, which are pre-\\ntrained on massive amounts of data. Note that we structurethe models in Fig. 1by their output modality such as X-to-\\ntext or X-to-image. For example, GPT-4 as the most recent\\ngenerative AI model underlying OpenAI’s popular con-versational agent ChatGPT (OpenAI 2023a ) accepts both\\nimage and text inputs to generate text outputs. Similarly,\\n1It should be noted, however, that advanced generative AI models\\nare often not based on a single modeling principle or learningmechanism, but combine different approaches. For example, language\\nmodels from the GPT family ﬁrst apply a generative pre-training',\n",
       " 'are often not based on a single modeling principle or learningmechanism, but combine different approaches. For example, language\\nmodels from the GPT family ﬁrst apply a generative pre-training\\nstage to capture the distribution of language data using a languagemodeling objective, while downstream systems typically then apply adiscriminative ﬁne-tuning stage to adapt the model parameters to\\nspeciﬁc tasks (e.g., document classiﬁcation, question answering).\\nSimilarly, ChatGPT combines techniques from generative modelingtogether with discriminatory modeling and reinforcement learning(see Fig. 2).\\n123112 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)',\n",
       " '123112 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Midjourney accepts both modalities to generate images. To\\nthis end, generative AI models can also be grouped intounimodal and multimodal models. Unimodal models take\\ninstructions from the same input type as their output (e.g.,\\ntext). On the other hand, multimodal models can take inputfrom different sources and generate output in various\\nforms. Multimodal models exist across a variety of data\\nmodalities, for example for text, image, and audio.Prominent examples include Stable Diffusion (Rombach\\net al. 2022 ) for text-to-image generation, MusicLM\\n(Agostinelli et al. 2023 ) for text-to-music generation,',\n",
       " 'et al. 2022 ) for text-to-image generation, MusicLM\\n(Agostinelli et al. 2023 ) for text-to-music generation,\\nCodex (Chen et al. 2021 ) and AlphaCode (Li et al. 2022 )\\nfor text-to-code generation, and as mentioned above GPT-4\\nfor image-to-text as well as text-to-text generation(OpenAI 2023a ).\\nThe underlying training procedures vary greatly across\\ndifferent generative AI models (see Fig. 2). For example,\\ngenerative adversarial networks (GANs) are trained\\nthrough two competing objectives (Goodfellow et al.\\n2014 ), where one is to create new synthetic samples while\\nthe other tries to detect synthetic samples from the actual\\ntraining samples, so that the distribution of synthetic\\nsamples is eventually close to the distribution of thetraining samples. Differently, systems such as ChatGPT-',\n",
       " 'training samples, so that the distribution of synthetic\\nsamples is eventually close to the distribution of thetraining samples. Differently, systems such as ChatGPT-\\nbased conversational models use reinforcement learning\\nfrom human feedback (RLHF). RLHF as used by ChatGPT\\nproceeds in three steps to ﬁrst create demonstration data for\\nprompts, then to have users rank the quality of differentoutputs for a prompt, and ﬁnally to learn a policy that\\ngenerates desirable output via reinforcement learning so\\nthat the output would score well during ranking (Ziegleret al. 2019 ).2.2.2 System-Level View\\nAny system consists of a number of elements that are\\ninterconnected and interact with each other. For generativeAI systems, this comprises not only the aforementioned',\n",
       " 'Any system consists of a number of elements that are\\ninterconnected and interact with each other. For generativeAI systems, this comprises not only the aforementioned\\ngenerative AI model but also the underlying infrastructure,\\nuser-facing components, and their modality as well as thecorresponding data processing (e.g., for prompts). An\\nexample would be the integration of deep learning models,\\nlike Codex (Chen et al. 2021 ), into a more interactive and\\ncomprehensive system, like GitHub Copilot, which allows\\nits users to code more efﬁciently. Similarly, Midjourney’s\\nimage generation system builds on an undisclosed X-to-image generation model that users can interact with to\\ngenerate images using Discord bots. Thus, generative AI\\nsystems embed the functionality of the underlying mathe-',\n",
       " 'generate images using Discord bots. Thus, generative AI\\nsystems embed the functionality of the underlying mathe-\\nmatical model to provide an interface for user interaction.\\nThis step augments the model-speciﬁc capabilities,enhancing its practicability and usability across real-world\\nuse cases.\\nCore concerns when embedding deep learning models in\\ngenerative AI systems generally are scalability (e.g., dis-\\ntributed computing resources), deployment (e.g., in various\\nenvironments and for different devices), and usability (e.g.,a user-friendly interface and intent recognition). As pre-\\ntrained open-source alternatives to closed-source, propri-\\netary models continue to be released, making these modelsavailable to their users (be it companies or individuals)',\n",
       " 'trained open-source alternatives to closed-source, propri-\\netary models continue to be released, making these modelsavailable to their users (be it companies or individuals)\\nbecomes increasingly important. For both open-source and\\nclosed-source models, unexpected deterioration of modelperformance over time highlights the need for continuous\\nmodel monitoring (Chen et al. 2023 ). Although powerful\\ntext-generating models existed before the release of theFig. 1 A model-, system-, and\\napplication-level view ongenerative AI\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 113\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Table 1 Glossary of key concepts in generative AI\\nConcept Description',\n",
       " 'Content courtesy of Springer Nature, terms of use apply. Rights reserved.Table 1 Glossary of key concepts in generative AI\\nConcept Description\\nDiffusion probabilistic models Diffusion probability models are a class of latent variable models that are common for various tasks such as\\nimage generation (Ho et al. 2020 ). Formally, diffusion probability models capture the image data by\\nmodeling the way data points diffuse through a latent space, which is inspired by statistical physics.\\nSpeciﬁcally, they typically use Markov chains trained with variational inference and then reverse the\\ndiffusion process to generate a natural image. A notable variant is Stable Diffusion (Rombach et al. 2022 ).\\nDiffusion probability models are also used in commercial systems such as DALL-E and Midjourney.',\n",
       " 'Diffusion probability models are also used in commercial systems such as DALL-E and Midjourney.\\nGenerative adversarial network A GAN is a class of neural network architecture with a custom, adversarial learning objective (Goodfellow\\net al. 2014 ). A GAN consists of two neural networks that contest with each other in the form of a zero-sum\\ngame, so that samples from a speciﬁc distribution can be generated. Formally, the ﬁrst network Gis called\\nthe generator, which generates candidate samples. The second network Dis called the discriminator, which\\nevaluates how likely the candidate samples come from a desired distribution. Thanks to the adversarial\\nlearning objective, the generator learns to map from a latent space to a data distribution of interest, while',\n",
       " 'learning objective, the generator learns to map from a latent space to a data distribution of interest, while\\nthe discriminator distinguishes candidates produced by the generator from the true data distribution (seeFig. 2).\\n(Large) language model A (large) language model (LLM) refers to neural networks for modeling and generating text data that\\ntypically combine three characteristics. First, the language model uses a large-scale, sequential neural\\nnetwork (e.g., transformer with an attention mechanism). Second, the neural network is pre-trained through\\nself-supervision in which auxiliary tasks are designed to learn a representation of natural language withoutrisk of overﬁtting (e.g., next-word prediction). Third, the pre-training makes use of large-scale datasets of',\n",
       " 'text (e.g., Wikipedia, or even multi-language datasets). Eventually, the language model may be ﬁne-tuned\\nby practitioners with custom datasets for speciﬁc tasks (e.g., question answering, natural languagegeneration). Recently, language models have evolved into so-called LLMs, which combine billions ofparameters. Prominent examples of massive LLMs are BERT (Devlin et al. 2018 ) and GPT-3 (Brown et al.\\n2020 ) with /C24340 million and /C24175 billion parameters, respectively.\\nReinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional',\n",
       " 'Reinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional\\nreinforcement learning, RLHF directly trains a so-called reward model from human feedback and then usesthe model as a reward function to optimize the policy, which is optimized through data-efﬁcient and robustalgorithms (Ziegler et al. 2019 ). RLHF is used in conversational systems such as ChatGPT (OpenAI 2022 )\\nfor generating chat messages, such that new answers accommodate the previous chat dialogue and ensure\\nthat the answers are in alignment with predeﬁned human preferences (e.g., length, style, appropriateness)\\nPrompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream',\n",
       " 'Prompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream\\ntasks (Liu et al. 2023 ). In general, prompt learning does not require any ﬁne-tuning of the language model,\\nwhich makes it efﬁcient and ﬂexible. A prompt is a speciﬁc input to a language model (e.g., ‘‘The movie\\nwas superb. Sentiment: ‘‘) and then the most probable output s2f‘‘positive’’ ;‘‘negative’’ ginstead of the\\nspace is picked. Recent advances allow for more complex data-driven prompt engineering, such as tuningprompts via reinforcement learning (Liu et al. 2023 ).\\nseq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is',\n",
       " 'seq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is\\nmapped onto an output sequence (Sutskever et al. 2014 ). An example is machine learning-based translation\\nbetween different languages. Such seq2seq approaches consist of two main components: An encoder turnseach element in a sequence (e.g., each word in a text) into a corresponding hidden vector containing the\\nelement and its context. The decoder reverses the process, turning the vector into an output element (e.g., a\\nword from the new language) while considering the previous output to model dependencies in language.The idea of seq2seq models has been extended to allow for multi-modal mappings such as text-to-image ortext-to-speech mappings.',\n",
       " 'Transformer A transformer is a deep learning architecture (Vaswani et al. 2017 ) that adopts the mechanism of self-\\nattention which differentially weights the importance of each part of the input data. Like recurrent neural\\nnetworks (RNNs), transformers are designed to process sequential input data, such as natural language, withapplications for tasks such as translation and text summarization. However, unlike RNNs, transformers\\nprocess the entire input all at once. The attention mechanism provides context for any position in the input',\n",
       " 'process the entire input all at once. The attention mechanism provides context for any position in the input\\nsequence. Eventually, the output of a transformer (or an RNN in general) is a document embedding, whichpresents a lower-dimensional representation of text (or other input) sequences where similar texts arelocated in closer proximity which typically beneﬁts downstream tasks as this allows to capture semantics\\nand meaning (Siebers et al. 2022 ).\\nVariational autoencoder A variational autoencoder (VAE) is a type of neural network that is trained to learn a low-dimensional',\n",
       " 'and meaning (Siebers et al. 2022 ).\\nVariational autoencoder A variational autoencoder (VAE) is a type of neural network that is trained to learn a low-dimensional\\nrepresentation of the input data by encoding it into a compressed latent variable space and thenreconstructing the original data from this compressed representation. VAEs differ from traditionalautoencoders by using a probabilistic approach to the encoding and decoding process, which enables them\\nto capture the underlying structure and variation in the data and generate new data samples from the learned\\nlatent space (Kingma and Welling 2013 ). This makes them useful for tasks such as anomaly detection and\\ndata compression but also image and text generation.',\n",
       " 'latent space (Kingma and Welling 2013 ). This makes them useful for tasks such as anomaly detection and\\ndata compression but also image and text generation.\\n123114 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.ChatGPT system in November 2022, ChatGPT’s ease of\\nuse also for non-expert users was a core contributing factor\\nto its explosive worldwide adoption.\\nMoreover, on the system level, multiple components of\\na generative AI system can be integrated or connected to\\nother systems, external databases with domain-speciﬁc\\nknowledge, or platforms. For example, common limitationsin many generative AI models are that they were trained on\\nhistorical data with speciﬁc cut-off date and thus do not',\n",
       " 'knowledge, or platforms. For example, common limitationsin many generative AI models are that they were trained on\\nhistorical data with speciﬁc cut-off date and thus do not\\nstore information beyond or that an information compres-sion takes place because of which generative AI models\\nmay not remember everything that they saw during training\\n(Chiang 2023 ). Both limitations can be mitigated by aug-\\nmenting the model with functionality for real-timeTable 1 continued\\nConcept Description\\nZero-shot learning / few-shot\\nlearningZero-shot learning and few-shot learning refer to different paradigms of how machine learning deals with\\nthe problem of data scarcity. Zero-shot learning is when a machine is taught how to learn a task from data',\n",
       " 'the problem of data scarcity. Zero-shot learning is when a machine is taught how to learn a task from data\\nwithout ever needing to access the data itself, while few-short learning refers to when there are only a fewspeciﬁc examples. Zero-shot learning and few-shot learning are often desirable in practice as they reducethe cost of setting up AI systems. LLMs are few-shot or zero-shot learners (Brown et al. 2020 ) as they just\\nneed a few samples to learn a task (e.g., predicting the sentiment of reviews), which makes LLMs highly\\nﬂexible as a general-purpose tool.\\nFig. 2 Examples of different training procedures for generative AI models. aGenerative adversarial network (GAN). bReinforcement learning\\nfrom human feedback (RLHF) as used in conversational generative AI models',\n",
       " 'from human feedback (RLHF) as used in conversational generative AI models\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 115\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.information retrieval, which can substantially enhance its\\naccuracy and usefulness. Relatedly, in the context of text\\ngeneration, online language modeling addresses the prob-\\nlem of outdated models by continuously training them onup-to-date data.\\n2Thereby, such models can then be\\nknowledgeable of recent events that their static counter-\\nparts would not be aware of due to their training cut-offdates.\\n2.2.3 Application-Level ViewGenerative AI applications are generative AI systems sit-\\nuated in organizations to deliver value by solving dedicated',\n",
       " '2.2.3 Application-Level ViewGenerative AI applications are generative AI systems sit-\\nuated in organizations to deliver value by solving dedicated\\nbusiness problems and addressing stakeholder needs. They\\ncan be regarded as human-task-technology systems orinformation systems that use generative AI technology to\\naugment human capacities to accomplish speciﬁc tasks.\\nThis level of generative AI encompasses countless real-world use cases: These range from SEO content generation\\n(Reisenbichler et al. 2022 ), over synthetic movie genera-\\ntion (Metz 2023 ) and AI music generation (Garcia 2023 ),\\nto natural language-based software development (Chen\\net al. 2021 ).\\nGenerative AI applications will give rise to novel\\ntechnology-enabled modes of work. The more users will',\n",
       " 'to natural language-based software development (Chen\\net al. 2021 ).\\nGenerative AI applications will give rise to novel\\ntechnology-enabled modes of work. The more users will\\nfamiliarize themselves with these novel applications, the\\nmore they will trust or mistrust them as well as use ordisuse them. Over time, applications will likely transition\\nfrom mundane tasks such as writing standard letters and\\ngetting a dinner reservation to more sensitive tasks such assoliciting medical or legal advice. They will involve more\\nconsequential decisions, which may even involve moral\\njudgment (Kru ¨gel et al. 2023 ). This ever-increasing scope\\nand pervasiveness of generative AI applications give rise to\\nan imminent need not only to provide prescriptions and',\n",
       " 'judgment (Kru ¨gel et al. 2023 ). This ever-increasing scope\\nand pervasiveness of generative AI applications give rise to\\nan imminent need not only to provide prescriptions and\\nprinciples for trustworthy and reliable designs, but also forscrutinizing the effects on the user to calibrate qualities\\nsuch as trust appropriately. The (continued) use and\\nadoption of such applications by end users and organiza-tions entails a number of fundamental socio-technical\\nconsiderations to descry innovation potential and affor-\\ndances of generative AI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what\\nconstitutes AI are continuously reﬁned, while the reference',\n",
       " 'dances of generative AI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what\\nconstitutes AI are continuously reﬁned, while the reference\\npoint of human intelligence stays comparatively constant(Berente et al. 2021 ). With generative AI, we are\\napproaching a further point of reﬁnement . In the past, the\\ncapability of AI was mostly understood to be analytic,\\nsuitable for decision-making tasks. Now, AI gains thecapability to perform generative tasks, suitable for content\\ncreation. While the procedure of content creation to some\\nrespect can still be considered analytic as it is inherentlyprobabilistic, its results can be creative or even artistic as\\ngenerative AI combines elements in novel ways. Further,',\n",
       " 'respect can still be considered analytic as it is inherentlyprobabilistic, its results can be creative or even artistic as\\ngenerative AI combines elements in novel ways. Further,\\nIT artifacts were considered passive as they were used\\ndirectly by humans. With the advent of agentic IT artifacts\\n(Baird and Maruping 2021 ) powered by LLMs (Park et al.\\n2023 ), this human agency primacy assumption needs to be\\nrevisited and impacts how we devise the relation between\\nhuman and AI based on their potency. Eventually, this mayrequire AI capability models to structure, explain, guide,\\nand constrain the different abilities of AI systems and their\\nuses as AI applications.\\nFocusing on the interaction between humans and AI, so\\nfar, for analytic AI, the concept of delegation has been',\n",
       " 'and constrain the different abilities of AI systems and their\\nuses as AI applications.\\nFocusing on the interaction between humans and AI, so\\nfar, for analytic AI, the concept of delegation has been\\ndiscussed to establish a hierarchy for decision-making(Baird and Maruping 2021 ). With generative AI, a human\\nuses prompts to engage with an AI system to create con-\\ntent, and the AI then interprets the human’s intentions andprovides feedback to presuppose further prompts. At ﬁrst\\nglance, this seems to follow a delegation pattern as well.\\nYet, the subsequent process does not, as the output of theAI can be suggestive to the other and will inform their\\nfurther involvement directly or subconsciously. Thus, the',\n",
       " 'Yet, the subsequent process does not, as the output of theAI can be suggestive to the other and will inform their\\nfurther involvement directly or subconsciously. Thus, the\\nprocess of creation rather follows a co-creation pattern, thatis, the practice of collaborating in different roles to align\\nand offer diverse insights to guide a design process\\n(Ramaswamy and Ozcan 2018 ). Using the lens of agentic\\nAI artifacts, initiation is not limited to humans.\\nThe abovementioned interactions also impact our cur-\\nrent understanding of hybrid intelligence as the integrationof humans and AI, leveraging the unique strengths of both.\\nHybrid intelligence argues to address the limitations of\\neach intelligence type by combining human intuition, cre-ativity, and empathy with the computational power, accu-',\n",
       " 'Hybrid intelligence argues to address the limitations of\\neach intelligence type by combining human intuition, cre-ativity, and empathy with the computational power, accu-\\nracy, and scalability of AI systems to achieve enhanced\\ndecision-making and problem-solving capabilities (Deller-mann et al. 2019 ). With generative AI and the AI’s capa-\\nbility to co-create, the understanding of what constitutes\\nthis collective intelligence begins to shift. Hence, novelhuman-AI interaction models and patterns may become\\nnecessary to explain and guide the behavior of humans and\\nAI systems to enable effective and efﬁcient use in AIapplications on the one hand and, on the other hand, to\\nensure envelopment of AI agency and reach (Asatiani et al.\\n2021 ).\\nOn a theoretical level, this shift in human-computer or',\n",
       " 'ensure envelopment of AI agency and reach (Asatiani et al.\\n2021 ).\\nOn a theoretical level, this shift in human-computer or\\nrather human-AI interaction fuels another important2Seehttps://github.com/huggingface/olm-datasets (accessed 25 Aug\\n2023) for a script that enables users to pull up-to-date data from theweb for training online language models, for instance, from CommonCrawl and Wikipedia.\\n123116 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.observation: The theory of mind is an established theoret-\\nical lens in psychology to describe the cognitive ability of\\nindividuals to understand and predict the mental states,\\nemotions, and intentions of others (Carlson et al. 2013 ;',\n",
       " 'ical lens in psychology to describe the cognitive ability of\\nindividuals to understand and predict the mental states,\\nemotions, and intentions of others (Carlson et al. 2013 ;\\nBaron-Cohen 1997 ; Gray et al. 2007 ). This skill is crucial\\nfor social interactions, as it facilitates empathy and allows\\nfor effective communication. Moreover, conferring a mindto an AI system can substantially drive usage intensity\\n(Hartmann et al. 2023a ). The development of a theory of\\nmind in humans is unconscious and evolves throughout an\\nindividual’s life. The more natural AI systems become in\\nterms of their interface and output, the more a theory ofmind for human-computer interactions becomes necessary.\\nResearch is already investigating how AI systems can',\n",
       " 'terms of their interface and output, the more a theory ofmind for human-computer interactions becomes necessary.\\nResearch is already investigating how AI systems can\\nbecome theory-of-mind-aware to better understand theirhuman counterpart (Rabinowitz et al. 2018 ;C¸ elikok et al.\\n2019 ). However, current AI systems hardly offer any cues\\nfor interactions. Thus, humans are rather void of a theory toexplain their understanding of intelligent behavior by AI\\nsystems, which becomes even more important in a co-\\ncreation environment that does not follow a task delegationpattern. A theory of the artiﬁcial mind that explains how\\nindividuals perceive and assume the states and rationale of\\nAI systems to better collaborate with them may alleviatesome of these concerns.',\n",
       " 'individuals perceive and assume the states and rationale of\\nAI systems to better collaborate with them may alleviatesome of these concerns.\\n3 Limitations of Current Generative AI\\nIn the following, we discuss four salient boundaries of\\ngenerative AI that, we argue, are important limitations in\\nreal-world applications. The following limitations are of\\ntechnical nature in that they refer to how current generativeAI models make inferences, and, hence, the limitations\\narise at the model level. Because of this, it is likely that\\nlimitations will persist in the long run, with system- andapplication-level implications.\\nIncorrect outputs. Generative AI models may produce\\noutput with errors. This is owed to the underlying nature ofmachine learning models relying on probabilistic algo-',\n",
       " 'Incorrect outputs. Generative AI models may produce\\noutput with errors. This is owed to the underlying nature ofmachine learning models relying on probabilistic algo-\\nrithms for making inferences. For example, generative AI\\nmodels generate the most probable response to a prompt,not necessarily the correct response. As such, challenges\\narise as, by now, outputs are indistinguishable from\\nauthentic content and may present misinformation ordeceive users (Spitale et al. 2023 ). In LLMs, this problem\\nin emergent behavior is called hallucination (Ji et al. 2023 ),\\nwhich refers to mistakes in the generated text that aresemantically or syntactically plausible but are actually\\nnonsensical or incorrect. In other words, the generative AI',\n",
       " 'which refers to mistakes in the generated text that aresemantically or syntactically plausible but are actually\\nnonsensical or incorrect. In other words, the generative AI\\nmodel produces content that is not based on any facts orevidence, but rather on its own assumptions or biases.Moreover, the output of generative AI, especially that of\\nLLMs, is typically not easily veriﬁable.\\nThe correctness of generative AI models is highly\\ndependent on the quality of training data and the accordinglearning process. Generative AI systems and applications\\ncan implement correctness checks to inhibit certain out-\\nputs. Yet, due to the black-box nature of state-of-the-art AImodels (Rai 2020 ), the usage of such systems critically\\nhinges on users’ trust in reliable outputs. The closed source',\n",
       " 'puts. Yet, due to the black-box nature of state-of-the-art AImodels (Rai 2020 ), the usage of such systems critically\\nhinges on users’ trust in reliable outputs. The closed source\\nof commercial off-the-shelf generative AI systems aggra-\\nvates this fact and prohibits further tuning and re-training\\nof the models. One solution for addressing the downstreamimplications of incorrect outputs is to use generative AI to\\nproduce explanations or references, which can then be\\nveriﬁed by users. However, such explanations are againprobabilistic and thus subject to errors; nevertheless, they\\nmay help users in their judgment and decision-making\\nwhen to accept outputs of generative AI and when not.\\nBias and fairness. Societal biases permeate everyday\\nhuman-generated content (Eskreis-Winkler and Fishbach']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629ae82-d81c-4d16-b4fb-af517ff78fdd",
   "metadata": {},
   "source": [
    "### Load the dataset into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bf12245-b868-43a5-bb0a-b1e9fe506bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:46.342418Z",
     "start_time": "2024-04-26T14:28:41.379240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 150 headlines.\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(texts)\n",
    "print(\"Inserted %i headlines.\" % len(texts))\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0facd7b-6868-4fce-bdf8-4ba707391f2c",
   "metadata": {},
   "source": [
    "### Run the Q/A cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f073095-dc07-4a5b-bbaf-84dd6218c891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T19:21:11.054205Z",
     "start_time": "2024-04-26T19:20:35.074474Z"
    }
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your question (or type 'quit' to exit):  what is generative AI?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"what is generative AI?\"\n",
      "ANSWER: \"Generative AI refers to computational techniques that are capable of generating seemingly new, meaningful content such as text, images, or audio from training data. It has the potential to transform industries that rely on creativity, innovation, and knowledge processing.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.9463] \"ing songs could only be performed by humans. Thisassumption has changed drastically  ...\"\n",
      "    [0.9463] \"ing songs could only be performed by humans. Thisassumption has changed drastically  ...\"\n",
      "    [0.9463] \"ing songs could only be performed by humans. Thisassumption has changed drastically  ...\"\n",
      "    [0.9447] \"models and systems could be used and combined with each\n",
      "other to form applications f ...\"\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "What's your next question (or type 'quit' to exit):  QUIT\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd0cde6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
