{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e558352f-7038-4fa7-bb2c-7efc88d14689",
   "metadata": {},
   "source": [
    "## Querying PDF using Langchain and Astra DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d5d8b9-3256-4b5b-bcee-1b429a03da12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T10:00:41.372561Z",
     "start_time": "2024-04-26T10:00:35.464208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-16.0.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\r\n",
      "Collecting numpy>=1.16.6 (from pyarrow)\r\n",
      "  Using cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (61 kB)\r\n",
      "Downloading pyarrow-16.0.0-cp39-cp39-macosx_11_0_arm64.whl (26.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m26.0/26.0 MB\u001B[0m \u001B[31m17.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached numpy-1.26.4-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\r\n",
      "Installing collected packages: numpy, pyarrow\r\n",
      "Successfully installed numpy-1.26.4 pyarrow-16.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\r\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\r\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\r\n",
      "Installing collected packages: python-dotenv\r\n",
      "Successfully installed python-dotenv-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:26:34.577550Z",
     "start_time": "2024-04-26T14:26:33.360649Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35d98af7-d331-48de-a290-4a7007e59304",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T10:00:56.082500Z",
     "start_time": "2024-04-26T10:00:43.521707Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q cassio datasets langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07e0e32-b0df-4e04-8479-c75c25d0ece1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T10:00:59.340967Z",
     "start_time": "2024-04-26T10:00:58.134699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\r\n",
      "  Using cached pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/ajsharma/PycharmProjects/LLM-Langchain-Projects/venv/lib/python3.9/site-packages (from PyPDF2) (4.9.0)\r\n",
      "Using cached pypdf2-3.0.1-py3-none-any.whl (232 kB)\r\n",
      "Installing collected packages: PyPDF2\r\n",
      "Successfully installed PyPDF2-3.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd456b9-590b-4842-9ba7-0239d31d78dd",
   "metadata": {},
   "source": [
    "### Import the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cff11319-86f8-463a-b39b-ee733e36e69d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:01.844630Z",
     "start_time": "2024-04-26T14:28:01.828997Z"
    }
   },
   "outputs": [],
   "source": [
    "# LangChain components \n",
    "from langchain.vectorstores.cassandra import Cassandra\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Support for dataset retrieval with Hugging Face\n",
    "from datasets import load_dataset\n",
    " \n",
    "import cassio\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0c10d-e077-46ce-a9bc-d5dea231ff53",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:08.456428Z",
     "start_time": "2024-04-26T14:28:08.446312Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5882ae0f-6edd-43fa-b197-9b6fcf534ea0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:11.243985Z",
     "start_time": "2024-04-26T14:28:11.238603Z"
    }
   },
   "outputs": [],
   "source": [
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_ID = os.getenv(\"ASTRA_DB_ID\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5456d86-3527-4d11-8a92-5aa1fa8d1fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:12.183330Z",
     "start_time": "2024-04-26T14:28:12.176133Z"
    }
   },
   "outputs": [],
   "source": [
    "# provide the path of  pdf file/files.\n",
    "pdfreader = PdfReader('Generative_AI.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c22959c-07d6-40a7-a2d5-cab567a9ec3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:14.036034Z",
     "start_time": "2024-04-26T14:28:13.208890Z"
    }
   },
   "outputs": [],
   "source": [
    "# read text from pdf\n",
    "raw_text = ''\n",
    "for i, page in enumerate(pdfreader.pages):\n",
    "    content = page.extract_text()\n",
    "    if content:\n",
    "        raw_text += content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e793533b-8ca3-4c03-8de9-fd0a94dbc016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:14.109066Z",
     "start_time": "2024-04-26T14:28:14.103418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'CATCHWORD\\nGenerative AI\\nStefan Feuerriegel •Jochen Hartmann •Christian Janiesch •\\nPatrick Zschech\\nReceived: 29 April 2023 / Accepted: 7 August 2023 / Published online: 12 September 2023\\n/C211The Author(s) 2023\\nKeywords Generative AI /C1Artiﬁcial intelligence /C1\\nDecision support /C1Content creation /C1Information systems\\n1 Introduction\\nTom Freston is credited with saying ‘‘Innovation is taking\\ntwo things that exist and putting them together in a new\\nway’’. For a long time in history, it has been the prevailingassumption that artistic, creative tasks such as writing\\npoems, creating software, designing fashion, and compos-\\ning songs could only be performed by humans. Thisassumption has changed drastically with recent advances in\\nartiﬁcial intelligence (AI) that can generate new content in\\nways that cannot be distinguished anymore from humancraftsmanship.The term generative AI refers to computational tech-\\nniques that are capable of generating seemingly new,\\nmeaningful content such as text, images, or audio fromtraining data. The widespread diffusion of this technology\\nwith examples such as Dall-E 2, GPT-4, and Copilot is\\ncurrently revolutionizing the way we work and communi-cate with each other. Generative AI systems can not only\\nbe used for artistic purposes to create new text mimicking\\nwriters or new images mimicking illustrators, but they canand will assist humans as intelligent question-answering\\nsystems. Here, applications include information technology\\n(IT) help desks where generative AI supports transitionalknowledge work tasks and mundane needs such as cooking\\nrecipes and medical advice. Industry reports suggest that\\ngenerative AI could raise global gross domestic product(GDP) by 7% and replace 300 million jobs of knowledge\\nworkers (Goldman Sachs 2023 ). Undoubtedly, this has\\ndrastic implications not only for the Business & Informa-tion Systems Engineering (BISE) community, where we\\nwill face revolutionary opportunities, but also challenges\\nand risks that we need to tackle and manage to steer the\\ntechnology and its use in a responsible and sustainable\\ndirection.\\nIn this Catchword article, we provide a conceptualiza-\\ntion of generative AI as an entity in socio-technical systems\\nand provide examples of models, systems, and applica-tions. Based on that, we introduce limitations of current\\ngenerative AI and provide an agenda for BISE research.\\nPrevious papers discuss generative AI around speciﬁcmethods such as language models (e.g., Teubner et al.\\n2023 ; Dwivedi et al. 2023 ; Scho ¨bel et al. 2023 ) or speciﬁc\\napplications such as marketing (e.g., Peres et al. 2023 ),\\ninnovation management (Burger et al. 2023 ), scholarly\\nresearch (e.g., Susarla et al. 2023 ; Davison et al. 2023 ),\\nand education (e.g., Kasneci et al. 2023 ; Gimpel et al.Accepted after one revision by Susanne Strahringer.\\nS. Feuerriegel ( &)\\nLMU Munich and Munich Center for Machine Learning,\\nGeschwister-Scholl-Platz 1, 80539 Munich, Germanye-mail: feuerriegel@lmu.de\\nJ. Hartmann\\nTechnical University of Munich, TUM School of Management,Arcisstr. 21, 80333 Munich, Germanye-mail: jochen.hartmann@tum.de\\nC. Janiesch\\nTU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund,Germanye-mail: christian.janiesch@tu-dortmund.de\\nP. Zschech\\nFAU Erlangen-Nu ¨rnberg, Lange Gasse 20, 90403 Nu ¨rnberg,\\nGermanye-mail: patrick.zschech@fau.de\\n123Bus Inf Syst Eng 66(1):111–126 (2024)\\nhttps://doi.org/10.1007/s12599-023-00834-7\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.2023 ). Different from these works, we focus on generative\\nAI in the context of information systems, and, to this end,\\nwe discuss several opportunities and challenges that are\\nunique to the BISE community and make suggestions forimpactful directions for BISE research.\\n2 Conceptualization\\n2.1 Mathematical Principles of Generative AIGenerative AI is primarily based on generative modeling,\\nwhich has distinctive mathematical differences from dis-\\ncriminative modeling (Ng and Jordan 2001 ) often used in\\ndata-driven decision support. In general, discriminativemodeling tries to separate data points Xinto different\\nclasses Yby learning decision boundaries between them\\n(e.g., in classiﬁcation tasks with Y2f0;1g). In contrast to\\nthat, generative modeling aims to infer some actual data\\ndistribution. Examples can be the joint probability distri-\\nbution P(X,Y) of both the inputs and the outputs or P(Y),\\nbut where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to\\nproduce new synthetic samples (e.g., generate new obser-vation-target-pairs ( X,Y) or new observations Xgiven a\\ntarget value Y) (Bishop 2006 ).\\nBuilding upon the above, a generative AI model refers to\\ngenerative modeling that is instantiated with a machine\\nlearning architecture (e.g., a deep neural network) and,\\ntherefore, can create new data samples based on learnedpatterns.\\n1Further, a generative AI system encompasses the\\nentire infrastructure, including the model, data processing,\\nand user interface components. The model serves as thecore component of the system, which facilitates interaction\\nand application within a broader context. Lastly, generative\\nAI applications refer to the practical use cases and imple-\\nmentations of these systems, such as search engine opti-\\nmization (SEO) content generation or code generation that\\nsolve real-world problems and drive innovation acrossvarious domains. Figure 1shows a systematization of\\ngenerative AI across selected data modalities (e.g., text,\\nimage, and audio) and the model-, system-, and application-level perspectives, which we detail in the following section.Note that the modalities in Fig. 1are neither complete\\nnor entirely distinctive and can be detailed further. In\\naddition, many unique use cases such as, for example,\\nmodeling functional properties of proteins (Unsal et al.2022 ) can be represented in another modality such as text.\\n2.2 A Model-, System-, and Application-Level View\\nof Generative AI\\n2.2.1 Model-Level ViewA generative AI model is a type of machine learning\\narchitecture that uses AI algorithms to create novel data\\ninstances, drawing upon the patterns and relationships\\nobserved in the training data. A generative AI model is ofcritically central yet incomplete nature, as it requires fur-\\nther ﬁne-tuning to speciﬁc tasks through systems and\\napplications.\\nDeep neural networks are particularly well suited for the\\npurpose of data generation, especially as deep neural net-\\nworks can be designed using different architectures tomodel different data types (Janiesch et al. 2021 ; Kraus\\net al. 2020 ), for example, sequential data such as human\\nlanguage or spatial data such as images. Table 1presents\\nan overview of the underlying concepts and model archi-\\ntectures that are common in the context of generative AI,\\nsuch as diffusion probabilistic models for text-to-imagegeneration or the transformer architecture and (large) lan-\\nguage models (LLMs) for text generation. GPT (short for\\ngenerative pre-trained transformer), for example, repre-sents a popular family of LLMs, used for text generation,\\nfor instance, in the conversational agent ChatGPT.\\nLarge generative AI models that can model output in\\nand across speciﬁc domains or speciﬁc data types in a\\ncomprehensive and versatile manner are oftentimes also\\ncalled foundation models (Bommasani et al. 2021 ). Due to\\ntheir size, they exhibit two key properties: emergence ,\\nmeaning the behavior is oftentimes implicitly induced\\nrather than explicitly constructed (e.g., GPT models cancreate calendar entries in the .ical format even though such\\nmodels were not explicitly trained to do so), and homog-\\nenization , where a wide range of systems and applications\\ncan now be powered by a single, consolidated model (e.g.,\\nCopilot can generate source code across a wide range of\\nprogramming languages).\\nFigure 1presents an overview of generative AI models\\nalong different, selected data modalities, which are pre-\\ntrained on massive amounts of data. Note that we structurethe models in Fig. 1by their output modality such as X-to-\\ntext or X-to-image. For example, GPT-4 as the most recent\\ngenerative AI model underlying OpenAI’s popular con-versational agent ChatGPT (OpenAI 2023a ) accepts both\\nimage and text inputs to generate text outputs. Similarly,\\n1It should be noted, however, that advanced generative AI models\\nare often not based on a single modeling principle or learningmechanism, but combine different approaches. For example, language\\nmodels from the GPT family ﬁrst apply a generative pre-training\\nstage to capture the distribution of language data using a languagemodeling objective, while downstream systems typically then apply adiscriminative ﬁne-tuning stage to adapt the model parameters to\\nspeciﬁc tasks (e.g., document classiﬁcation, question answering).\\nSimilarly, ChatGPT combines techniques from generative modelingtogether with discriminatory modeling and reinforcement learning(see Fig. 2).\\n123112 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Midjourney accepts both modalities to generate images. To\\nthis end, generative AI models can also be grouped intounimodal and multimodal models. Unimodal models take\\ninstructions from the same input type as their output (e.g.,\\ntext). On the other hand, multimodal models can take inputfrom different sources and generate output in various\\nforms. Multimodal models exist across a variety of data\\nmodalities, for example for text, image, and audio.Prominent examples include Stable Diffusion (Rombach\\net al. 2022 ) for text-to-image generation, MusicLM\\n(Agostinelli et al. 2023 ) for text-to-music generation,\\nCodex (Chen et al. 2021 ) and AlphaCode (Li et al. 2022 )\\nfor text-to-code generation, and as mentioned above GPT-4\\nfor image-to-text as well as text-to-text generation(OpenAI 2023a ).\\nThe underlying training procedures vary greatly across\\ndifferent generative AI models (see Fig. 2). For example,\\ngenerative adversarial networks (GANs) are trained\\nthrough two competing objectives (Goodfellow et al.\\n2014 ), where one is to create new synthetic samples while\\nthe other tries to detect synthetic samples from the actual\\ntraining samples, so that the distribution of synthetic\\nsamples is eventually close to the distribution of thetraining samples. Differently, systems such as ChatGPT-\\nbased conversational models use reinforcement learning\\nfrom human feedback (RLHF). RLHF as used by ChatGPT\\nproceeds in three steps to ﬁrst create demonstration data for\\nprompts, then to have users rank the quality of differentoutputs for a prompt, and ﬁnally to learn a policy that\\ngenerates desirable output via reinforcement learning so\\nthat the output would score well during ranking (Ziegleret al. 2019 ).2.2.2 System-Level View\\nAny system consists of a number of elements that are\\ninterconnected and interact with each other. For generativeAI systems, this comprises not only the aforementioned\\ngenerative AI model but also the underlying infrastructure,\\nuser-facing components, and their modality as well as thecorresponding data processing (e.g., for prompts). An\\nexample would be the integration of deep learning models,\\nlike Codex (Chen et al. 2021 ), into a more interactive and\\ncomprehensive system, like GitHub Copilot, which allows\\nits users to code more efﬁciently. Similarly, Midjourney’s\\nimage generation system builds on an undisclosed X-to-image generation model that users can interact with to\\ngenerate images using Discord bots. Thus, generative AI\\nsystems embed the functionality of the underlying mathe-\\nmatical model to provide an interface for user interaction.\\nThis step augments the model-speciﬁc capabilities,enhancing its practicability and usability across real-world\\nuse cases.\\nCore concerns when embedding deep learning models in\\ngenerative AI systems generally are scalability (e.g., dis-\\ntributed computing resources), deployment (e.g., in various\\nenvironments and for different devices), and usability (e.g.,a user-friendly interface and intent recognition). As pre-\\ntrained open-source alternatives to closed-source, propri-\\netary models continue to be released, making these modelsavailable to their users (be it companies or individuals)\\nbecomes increasingly important. For both open-source and\\nclosed-source models, unexpected deterioration of modelperformance over time highlights the need for continuous\\nmodel monitoring (Chen et al. 2023 ). Although powerful\\ntext-generating models existed before the release of theFig. 1 A model-, system-, and\\napplication-level view ongenerative AI\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 113\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Table 1 Glossary of key concepts in generative AI\\nConcept Description\\nDiffusion probabilistic models Diffusion probability models are a class of latent variable models that are common for various tasks such as\\nimage generation (Ho et al. 2020 ). Formally, diffusion probability models capture the image data by\\nmodeling the way data points diffuse through a latent space, which is inspired by statistical physics.\\nSpeciﬁcally, they typically use Markov chains trained with variational inference and then reverse the\\ndiffusion process to generate a natural image. A notable variant is Stable Diffusion (Rombach et al. 2022 ).\\nDiffusion probability models are also used in commercial systems such as DALL-E and Midjourney.\\nGenerative adversarial network A GAN is a class of neural network architecture with a custom, adversarial learning objective (Goodfellow\\net al. 2014 ). A GAN consists of two neural networks that contest with each other in the form of a zero-sum\\ngame, so that samples from a speciﬁc distribution can be generated. Formally, the ﬁrst network Gis called\\nthe generator, which generates candidate samples. The second network Dis called the discriminator, which\\nevaluates how likely the candidate samples come from a desired distribution. Thanks to the adversarial\\nlearning objective, the generator learns to map from a latent space to a data distribution of interest, while\\nthe discriminator distinguishes candidates produced by the generator from the true data distribution (seeFig. 2).\\n(Large) language model A (large) language model (LLM) refers to neural networks for modeling and generating text data that\\ntypically combine three characteristics. First, the language model uses a large-scale, sequential neural\\nnetwork (e.g., transformer with an attention mechanism). Second, the neural network is pre-trained through\\nself-supervision in which auxiliary tasks are designed to learn a representation of natural language withoutrisk of overﬁtting (e.g., next-word prediction). Third, the pre-training makes use of large-scale datasets of\\ntext (e.g., Wikipedia, or even multi-language datasets). Eventually, the language model may be ﬁne-tuned\\nby practitioners with custom datasets for speciﬁc tasks (e.g., question answering, natural languagegeneration). Recently, language models have evolved into so-called LLMs, which combine billions ofparameters. Prominent examples of massive LLMs are BERT (Devlin et al. 2018 ) and GPT-3 (Brown et al.\\n2020 ) with /C24340 million and /C24175 billion parameters, respectively.\\nReinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional\\nreinforcement learning, RLHF directly trains a so-called reward model from human feedback and then usesthe model as a reward function to optimize the policy, which is optimized through data-efﬁcient and robustalgorithms (Ziegler et al. 2019 ). RLHF is used in conversational systems such as ChatGPT (OpenAI 2022 )\\nfor generating chat messages, such that new answers accommodate the previous chat dialogue and ensure\\nthat the answers are in alignment with predeﬁned human preferences (e.g., length, style, appropriateness)\\nPrompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream\\ntasks (Liu et al. 2023 ). In general, prompt learning does not require any ﬁne-tuning of the language model,\\nwhich makes it efﬁcient and ﬂexible. A prompt is a speciﬁc input to a language model (e.g., ‘‘The movie\\nwas superb. Sentiment: ‘‘) and then the most probable output s2f‘‘positive’’ ;‘‘negative’’ ginstead of the\\nspace is picked. Recent advances allow for more complex data-driven prompt engineering, such as tuningprompts via reinforcement learning (Liu et al. 2023 ).\\nseq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is\\nmapped onto an output sequence (Sutskever et al. 2014 ). An example is machine learning-based translation\\nbetween different languages. Such seq2seq approaches consist of two main components: An encoder turnseach element in a sequence (e.g., each word in a text) into a corresponding hidden vector containing the\\nelement and its context. The decoder reverses the process, turning the vector into an output element (e.g., a\\nword from the new language) while considering the previous output to model dependencies in language.The idea of seq2seq models has been extended to allow for multi-modal mappings such as text-to-image ortext-to-speech mappings.\\nTransformer A transformer is a deep learning architecture (Vaswani et al. 2017 ) that adopts the mechanism of self-\\nattention which differentially weights the importance of each part of the input data. Like recurrent neural\\nnetworks (RNNs), transformers are designed to process sequential input data, such as natural language, withapplications for tasks such as translation and text summarization. However, unlike RNNs, transformers\\nprocess the entire input all at once. The attention mechanism provides context for any position in the input\\nsequence. Eventually, the output of a transformer (or an RNN in general) is a document embedding, whichpresents a lower-dimensional representation of text (or other input) sequences where similar texts arelocated in closer proximity which typically beneﬁts downstream tasks as this allows to capture semantics\\nand meaning (Siebers et al. 2022 ).\\nVariational autoencoder A variational autoencoder (VAE) is a type of neural network that is trained to learn a low-dimensional\\nrepresentation of the input data by encoding it into a compressed latent variable space and thenreconstructing the original data from this compressed representation. VAEs differ from traditionalautoencoders by using a probabilistic approach to the encoding and decoding process, which enables them\\nto capture the underlying structure and variation in the data and generate new data samples from the learned\\nlatent space (Kingma and Welling 2013 ). This makes them useful for tasks such as anomaly detection and\\ndata compression but also image and text generation.\\n123114 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.ChatGPT system in November 2022, ChatGPT’s ease of\\nuse also for non-expert users was a core contributing factor\\nto its explosive worldwide adoption.\\nMoreover, on the system level, multiple components of\\na generative AI system can be integrated or connected to\\nother systems, external databases with domain-speciﬁc\\nknowledge, or platforms. For example, common limitationsin many generative AI models are that they were trained on\\nhistorical data with speciﬁc cut-off date and thus do not\\nstore information beyond or that an information compres-sion takes place because of which generative AI models\\nmay not remember everything that they saw during training\\n(Chiang 2023 ). Both limitations can be mitigated by aug-\\nmenting the model with functionality for real-timeTable 1 continued\\nConcept Description\\nZero-shot learning / few-shot\\nlearningZero-shot learning and few-shot learning refer to different paradigms of how machine learning deals with\\nthe problem of data scarcity. Zero-shot learning is when a machine is taught how to learn a task from data\\nwithout ever needing to access the data itself, while few-short learning refers to when there are only a fewspeciﬁc examples. Zero-shot learning and few-shot learning are often desirable in practice as they reducethe cost of setting up AI systems. LLMs are few-shot or zero-shot learners (Brown et al. 2020 ) as they just\\nneed a few samples to learn a task (e.g., predicting the sentiment of reviews), which makes LLMs highly\\nﬂexible as a general-purpose tool.\\nFig. 2 Examples of different training procedures for generative AI models. aGenerative adversarial network (GAN). bReinforcement learning\\nfrom human feedback (RLHF) as used in conversational generative AI models\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 115\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.information retrieval, which can substantially enhance its\\naccuracy and usefulness. Relatedly, in the context of text\\ngeneration, online language modeling addresses the prob-\\nlem of outdated models by continuously training them onup-to-date data.\\n2Thereby, such models can then be\\nknowledgeable of recent events that their static counter-\\nparts would not be aware of due to their training cut-offdates.\\n2.2.3 Application-Level ViewGenerative AI applications are generative AI systems sit-\\nuated in organizations to deliver value by solving dedicated\\nbusiness problems and addressing stakeholder needs. They\\ncan be regarded as human-task-technology systems orinformation systems that use generative AI technology to\\naugment human capacities to accomplish speciﬁc tasks.\\nThis level of generative AI encompasses countless real-world use cases: These range from SEO content generation\\n(Reisenbichler et al. 2022 ), over synthetic movie genera-\\ntion (Metz 2023 ) and AI music generation (Garcia 2023 ),\\nto natural language-based software development (Chen\\net al. 2021 ).\\nGenerative AI applications will give rise to novel\\ntechnology-enabled modes of work. The more users will\\nfamiliarize themselves with these novel applications, the\\nmore they will trust or mistrust them as well as use ordisuse them. Over time, applications will likely transition\\nfrom mundane tasks such as writing standard letters and\\ngetting a dinner reservation to more sensitive tasks such assoliciting medical or legal advice. They will involve more\\nconsequential decisions, which may even involve moral\\njudgment (Kru ¨gel et al. 2023 ). This ever-increasing scope\\nand pervasiveness of generative AI applications give rise to\\nan imminent need not only to provide prescriptions and\\nprinciples for trustworthy and reliable designs, but also forscrutinizing the effects on the user to calibrate qualities\\nsuch as trust appropriately. The (continued) use and\\nadoption of such applications by end users and organiza-tions entails a number of fundamental socio-technical\\nconsiderations to descry innovation potential and affor-\\ndances of generative AI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what\\nconstitutes AI are continuously reﬁned, while the reference\\npoint of human intelligence stays comparatively constant(Berente et al. 2021 ). With generative AI, we are\\napproaching a further point of reﬁnement . In the past, the\\ncapability of AI was mostly understood to be analytic,\\nsuitable for decision-making tasks. Now, AI gains thecapability to perform generative tasks, suitable for content\\ncreation. While the procedure of content creation to some\\nrespect can still be considered analytic as it is inherentlyprobabilistic, its results can be creative or even artistic as\\ngenerative AI combines elements in novel ways. Further,\\nIT artifacts were considered passive as they were used\\ndirectly by humans. With the advent of agentic IT artifacts\\n(Baird and Maruping 2021 ) powered by LLMs (Park et al.\\n2023 ), this human agency primacy assumption needs to be\\nrevisited and impacts how we devise the relation between\\nhuman and AI based on their potency. Eventually, this mayrequire AI capability models to structure, explain, guide,\\nand constrain the different abilities of AI systems and their\\nuses as AI applications.\\nFocusing on the interaction between humans and AI, so\\nfar, for analytic AI, the concept of delegation has been\\ndiscussed to establish a hierarchy for decision-making(Baird and Maruping 2021 ). With generative AI, a human\\nuses prompts to engage with an AI system to create con-\\ntent, and the AI then interprets the human’s intentions andprovides feedback to presuppose further prompts. At ﬁrst\\nglance, this seems to follow a delegation pattern as well.\\nYet, the subsequent process does not, as the output of theAI can be suggestive to the other and will inform their\\nfurther involvement directly or subconsciously. Thus, the\\nprocess of creation rather follows a co-creation pattern, thatis, the practice of collaborating in different roles to align\\nand offer diverse insights to guide a design process\\n(Ramaswamy and Ozcan 2018 ). Using the lens of agentic\\nAI artifacts, initiation is not limited to humans.\\nThe abovementioned interactions also impact our cur-\\nrent understanding of hybrid intelligence as the integrationof humans and AI, leveraging the unique strengths of both.\\nHybrid intelligence argues to address the limitations of\\neach intelligence type by combining human intuition, cre-ativity, and empathy with the computational power, accu-\\nracy, and scalability of AI systems to achieve enhanced\\ndecision-making and problem-solving capabilities (Deller-mann et al. 2019 ). With generative AI and the AI’s capa-\\nbility to co-create, the understanding of what constitutes\\nthis collective intelligence begins to shift. Hence, novelhuman-AI interaction models and patterns may become\\nnecessary to explain and guide the behavior of humans and\\nAI systems to enable effective and efﬁcient use in AIapplications on the one hand and, on the other hand, to\\nensure envelopment of AI agency and reach (Asatiani et al.\\n2021 ).\\nOn a theoretical level, this shift in human-computer or\\nrather human-AI interaction fuels another important2Seehttps://github.com/huggingface/olm-datasets (accessed 25 Aug\\n2023) for a script that enables users to pull up-to-date data from theweb for training online language models, for instance, from CommonCrawl and Wikipedia.\\n123116 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.observation: The theory of mind is an established theoret-\\nical lens in psychology to describe the cognitive ability of\\nindividuals to understand and predict the mental states,\\nemotions, and intentions of others (Carlson et al. 2013 ;\\nBaron-Cohen 1997 ; Gray et al. 2007 ). This skill is crucial\\nfor social interactions, as it facilitates empathy and allows\\nfor effective communication. Moreover, conferring a mindto an AI system can substantially drive usage intensity\\n(Hartmann et al. 2023a ). The development of a theory of\\nmind in humans is unconscious and evolves throughout an\\nindividual’s life. The more natural AI systems become in\\nterms of their interface and output, the more a theory ofmind for human-computer interactions becomes necessary.\\nResearch is already investigating how AI systems can\\nbecome theory-of-mind-aware to better understand theirhuman counterpart (Rabinowitz et al. 2018 ;C¸ elikok et al.\\n2019 ). However, current AI systems hardly offer any cues\\nfor interactions. Thus, humans are rather void of a theory toexplain their understanding of intelligent behavior by AI\\nsystems, which becomes even more important in a co-\\ncreation environment that does not follow a task delegationpattern. A theory of the artiﬁcial mind that explains how\\nindividuals perceive and assume the states and rationale of\\nAI systems to better collaborate with them may alleviatesome of these concerns.\\n3 Limitations of Current Generative AI\\nIn the following, we discuss four salient boundaries of\\ngenerative AI that, we argue, are important limitations in\\nreal-world applications. The following limitations are of\\ntechnical nature in that they refer to how current generativeAI models make inferences, and, hence, the limitations\\narise at the model level. Because of this, it is likely that\\nlimitations will persist in the long run, with system- andapplication-level implications.\\nIncorrect outputs. Generative AI models may produce\\noutput with errors. This is owed to the underlying nature ofmachine learning models relying on probabilistic algo-\\nrithms for making inferences. For example, generative AI\\nmodels generate the most probable response to a prompt,not necessarily the correct response. As such, challenges\\narise as, by now, outputs are indistinguishable from\\nauthentic content and may present misinformation ordeceive users (Spitale et al. 2023 ). In LLMs, this problem\\nin emergent behavior is called hallucination (Ji et al. 2023 ),\\nwhich refers to mistakes in the generated text that aresemantically or syntactically plausible but are actually\\nnonsensical or incorrect. In other words, the generative AI\\nmodel produces content that is not based on any facts orevidence, but rather on its own assumptions or biases.Moreover, the output of generative AI, especially that of\\nLLMs, is typically not easily veriﬁable.\\nThe correctness of generative AI models is highly\\ndependent on the quality of training data and the accordinglearning process. Generative AI systems and applications\\ncan implement correctness checks to inhibit certain out-\\nputs. Yet, due to the black-box nature of state-of-the-art AImodels (Rai 2020 ), the usage of such systems critically\\nhinges on users’ trust in reliable outputs. The closed source\\nof commercial off-the-shelf generative AI systems aggra-\\nvates this fact and prohibits further tuning and re-training\\nof the models. One solution for addressing the downstreamimplications of incorrect outputs is to use generative AI to\\nproduce explanations or references, which can then be\\nveriﬁed by users. However, such explanations are againprobabilistic and thus subject to errors; nevertheless, they\\nmay help users in their judgment and decision-making\\nwhen to accept outputs of generative AI and when not.\\nBias and fairness. Societal biases permeate everyday\\nhuman-generated content (Eskreis-Winkler and Fishbach\\n2022 ). The unbiasedness of vanilla generative AI is very\\nmuch dependent on the quality of training data and the\\nalignment process. Training deep learning models on\\nbiased data can amplify human biases, replicate toxiclanguage, or perpetuate stereotypes of gender, sexual ori-\\nentation, political leaning, or religion (e.g., Caliskan et al.\\n2017 ; Hartmann et al. 2023b ). Recent studies expose the\\nharmful biases embedded in multimodal generative AI\\nmodels such as CLIP (contrastive language-image pre-\\ntraining; Wolfe et al. 2022 ) and the CLIP-ﬁltered LAION\\ndataset (Birhane et al. 2021 ), which are core components\\nof generative AI models (e.g., Dall-E 2 or Stable Diffu-\\nsion). Human biases can also creep into the models in otherstages of the model engineering process. For instruction-\\nbased language models, the RLHF process is an additional\\nsource of bias (OpenAI 2023b ). Careful coding guidelines\\nand quality checks can help address these risks.\\nAddressing bias and thus fairness in AI receives\\nincreasing attention in the academic literature (Dolata et al.\\n2022 ; Schramowski et al. 2022 ; Ferrara 2023 ; De-Arteaga\\net al. 2022 ; Feuerriegel et al. 2020 ; von Zahn et al. 2022 ),\\nbut remains an open and ongoing research question. Forexample, the developers of Stable Diffusion ﬂag ‘‘probing\\nand understanding the limitations and biases of generative\\nmodels’’ as an important research area (Rombach et al.2022 ). Some scholars even attest to models certain moral\\nself-correcting capabilities (Ganguli et al. 2023 ), which\\nmay attenuate concerns of embedded biases and result inmore fairness. In addition, on the system and application\\nlevel, mitigation mechanisms can be implemented to\\naddress biases embedded in the deep learning models andcreate more diverse outputs (e.g., updating the prompts\\n‘‘under the hood’’ as done by Dall-E 2 to increase the\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 117\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.demographic diversity of the outputs). Yet, more research\\nis needed to get closer to the notion of fair AI.\\nCopyright violation. Generative AI models, systems,\\nand applications may cause a violation of copyright lawsbecause they can produce outputs that resemble or even\\ncopy existing works without permission or compensation to\\nthe original creators (Smits and Borghuis 2022 ). Here, two\\npotential infringement risks are common. On the one hand,\\ngenerative AI may make illegal copies of a work, thus\\nviolating the reproduction right of creators. Among others,\\nthis may happen when a generative AI was trained on\\noriginal content that is protected by copyright but wherethe generative AI produces copies. Hence, a typical\\nimplication is that the training data for building generative\\nAI systems must be free of copyrights. Crucially, copyrightviolation may nevertheless still happen even when the\\ngenerative AI has never seen a copyrighted work before,\\nsuch as, for example, when it simply produces a trade-marked logo similar to that of Adidas but without\\never having seen that logo before. On the other hand,\\ngenerative AI may prepare derivative works, thus violatingthe transformation right of creators. To this end, legal\\nquestions arise around the balance of originality and cre-\\nativity in generative AI systems. Along these lines, legalquestions also arise around who holds the intellectual\\nproperty for works (including patents) produced by a\\ngenerative AI.\\nEnvironmental concerns. Lastly, there are substantial\\nenvironmental concerns from developing and using gen-\\nerative AI systems due to the fact that such systems aretypically built around large-scale neural networks, and,\\ntherefore, their development and operation consume large\\namounts of electricity with immense negative carbonfootprint (Schwartz et al. 2020 ). For example, the carbon\\nemission for training a generative AI model such as GPT-3\\nwas estimated to have produced the equivalent of552 t CO\\n2and thus amounts to the annual CO 2emissions\\nof several dozens of households (Khan 2021 ). Owing to\\nthis, there are ongoing efforts in AI research to make thedevelopment and deployment of AI algorithms more car-\\nbon-friendly, through more efﬁcient training algorithms,\\nthrough compressing the size of neural network architec-tures, and through optimized hardware (Schwartz et al.\\n2020 ).\\n4 Implications and Future Directions for the BISE\\nCommunity\\nIn this section, we draw a number of implications and\\nfuture research directions which, on the one hand, are ofdirect relevance to the BISE community as an application-\\noriented, socio-technical research discipline and, on theother hand, offer numerous research opportunities, espe-\\ncially for BISE researchers due to their interdisciplinary\\nbackground. We organize our considerations according to\\nthe individual departments of the BISE journal (seeTable 2for an overview of exemplary research questions).\\n4.1 Business Process ManagementGenerative AI will have a strong impact on the ﬁeld of\\nBusiness Process Management (BPM) as it can assist in\\nautomating routine tasks, improving customer and\\nemployee satisfaction, and revealing process innovationopportunities (Beverungen et al. 2021 ), especially in cre-\\native processes (Haase and Hanel 2023 ). Concrete impli-\\ncations and research directions can be connected to variousphases of the BPM lifecycle model (Vidgof et al. 2023 ).\\nFor example, in the context of process discovery, genera-\\ntive AI models could be used to generate processdescriptions, which can help businesses identify and\\nunderstand the different stages of a process (Kecht et al.\\n2023 ). From the perspective of business process improve-\\nment, generative process models could be used for idea\\ngeneration and to support innovative process (re-)design\\ninitiatives (van Dun et al. 2023 ). In this regard, there is\\ngreat potential for generative AI to contribute to both\\nexploitative as well as explorative BPM design strategies\\n(Grisold et al. 2022 ). In addition, natural language pro-\\ncessing tasks related to BPM such as process extraction\\nfrom text could beneﬁt from generative AI without further\\nﬁne-tuning using prompt engineering (Busch et al. 2023 ).\\nLikewise, other phases can beneﬁt owing to generative\\nAI’s ability to learn complex and non-linear relationships\\nin dynamic business processes that can be used forimplementation as well as in simulation and predictive\\nprocess monitoring among other things.\\nIn the short term, robotic process automation (van der\\nAalst et al. 2018 ; Herm et al. 2021 ) will beneﬁt as formerly\\nhandcrafted processing rules can not only be replaced, but\\nentirely new types of automation can be enabled by ret-roﬁtting and thus intelligentizing legacy software. In the\\nlong run, we also see a large potential to support the phase\\nof business process execution in traditional BPM. Speciﬁ-cally, we anticipate the development of a new generation of\\nprocess guidance systems. While traditional system designs\\nare based on static and manually-crafted knowledge bases(Morana et al. 2019 ), more dynamic and adaptive systems\\nare feasible on the basis of large enterprise-wide trained\\nlanguage models. Such systems could improve knowledgeretrieval tasks from a wide variety of heterogeneous sour-\\nces, including manuals, handbooks, e-mails, wikis, job\\ndescriptions, etc. This opens up new avenues of researchinto how unstructured and distributed organizational\\n123118 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.knowledge can be incorporated into intelligent process\\nguidance systems.\\n4.2 Decision Analytics and Data Science\\nDespite the huge progress in recent years, several analytical\\nand technical questions around the development of gener-\\native AI have yet to be solved. One open question relates to\\nhow generative AI can be effectively customized fordomain-speciﬁc applications and thus improve perfor-\\nmance through higher degrees of contextualization. For\\nexample, novel and scalable techniques are needed tocustomize conversational agents based on generative AI for\\napplications in medicine or ﬁnance. This will be crucial in\\npractice to solve speciﬁc BISE-related tasks where cus-tomization may bring additional performance gains. Novel\\ntechniques for customization must be designed in a way\\nthat ensures the safety of proprietary data and prevents thedata from being disclosed. Moreover, new frameworks are\\nneeded for prompt engineering that are designed from a\\nuser-centered lens and thus promote interpretability and\\nusability.\\nAnother important research direction is to improve the\\nreliability of generative AI systems. For example, algo-\\nrithmic solutions are needed on how generative AI can\\ndetect and mitigate hallucination. In addition to algorithmicsolutions, more effort is also needed to develop user-cen-\\ntered solutions, that is, how users can reduce the risk of\\nfalling for incorrect outcomes, for example, by developingbetter ways how outputs can be veriﬁed (e.g., by offering\\nadditional explanations or references).\\nFinally, questions arise about how generative AI can\\nnatively support decision analytics and data science pro-\\njects by closing the gap between modeling experts and\\ndomain users (Zschech et al. 2020 ). For instance, it is\\ncommonly known that many AI models used in business\\nanalytics are difﬁcult to understand by non-experts (cf.\\nSenoner et al. 2022 ). As a remedy, generative AI could be\\nused to generate descriptions that explain the logic of\\nbusiness analytics models and thus make the decision logic\\nmore intelligible. One promising direction could be, forexample, to use generative AI for translating post hoc\\nexplanations derived from approaches like SHAP or LIME\\ninto more intuitive textual descriptions or generate user-friendly descriptions of models that are intrinsically inter-\\npretable (Slack et al. 2023 ; Zilker et al. 2023 ).\\n4.3 Digital Business Management and Digital\\nLeadership\\nGenerative AI has great potential to contribute to different\\ntypes of value creation mechanisms, including knowledgecreation, task augmentation, and autonomous agency.\\nHowever, this also requires the necessary organizational\\ncapabilities and conditions, where further research is nee-ded to examine these ingredients more closely for the\\ncontext of generative AI to steer the technological possi-\\nbilities in a successful direction (Shollo et al. 2022 ).Table 2 Examples of research questions for future BISE research on generative AI\\nBISE department Research questions (examples)\\nBusiness process management How can generative AI assist in automating routine tasks?\\nHow can generative AI reveal process innovation opportunities and support process (re-)design\\ninitiatives?\\nDecision analytics and data science How can generative AI models be effectively ﬁne-tuned for domain-speciﬁc applications?\\nHow can the reliability of generative AI systems be improved?\\nDigital business management and digital\\nleadershipHow can generative AI support managerial tasks such as resource allocation?\\nHow will the digital work of employees change with smart assistants powered by generative AI?\\nEconomics of information systems What are the welfare implications of generative AI?\\nWhich jobs and tasks are affected most by generative AI?\\nEnterprise modeling and enterprise\\nengineeringHow can generative AI be used to support the construction and maintenance of enterprise models?\\nHow can generative AI support in enterprise applications (e.g., CRM, BI, etc.)?\\nHuman computer interaction and social\\ncomputingHow should generative AI systems be designed to foster trust?\\nWhat countermeasures are effective to prevent users from falling for AI-generated disinformation?To what extent can generative AI replace or augment crowdsourcing tasks?How can generative AI assist in education?\\nInformation systems engineering and\\ntechnologyWhat are effective design principles for developing generative AI systems?\\nHow can generative AI support design science projects to foster creativity in the development of\\nnew IT artifacts?\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 119\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.That is, generative AI will lead to the development of\\nnew business ideas, unseen product and service innova-\\ntions, and ultimately to the emergence of completely new\\nbusiness models. At the same time, it will also have astrong impact on intra-organizational aspects, such as work\\npatterns, organizational structures, leadership models, and\\nmanagement practices. In this regard, we see that AI-basedassistant systems previously centered around desktop\\nautomation taking over more and more routine tasks such\\nas event management, resource allocation, and social\\nmedia account management to free up even more human\\ncapacity (Maedche et al. 2019 ). Further, in algorithmic\\nmanagement (Benlian et al. 2022 ; Cameron et al. 2023 ), it\\nshould be examined how existing theories and frameworks\\nneed to be contextualized or fundamentally extended inlight of the increasingly powerful capabilities of generative\\nAI.\\nHowever, there are not only implications at the man-\\nagement level. The future of work is very likely to change\\nat all levels of an organization (Feuerriegel et al. 2022 ).\\nDue to the multi-modality of generative AI models, it isconceivable that employees will work increasingly via\\nsmart, speech-based interfaces, whereby the formulation of\\nprompts and the evaluation of their results could become akey activity. Against this background, it is worth investi-\\ngating which new competencies are required to handle this\\nemerging technology (cf. Debortoli et al. 2014 ) and which\\nentirely new job proﬁles, such as prompt engineers, may\\nevolve in the near future (Strobelt et al. 2023 ).\\nGenerative AI is also expected to fundamentally reform\\nthe way organizations manage, maintain, and share\\nknowledge. Referring to the sketched vision of a new\\nprocess guidance system in Sect. 4.1, we anticipate a\\nnumber of new opportunities for digital knowledge man-\\nagement, among others automated knowledge discovery\\nbased on large amounts of unstructured distributed data(e.g., identiﬁcation of new product combinations),\\nimproved knowledge sharing by automating the process of\\ncreating, summarizing, and disseminating content (e.g.,automated creation of wikis and FAQs in different lan-\\nguages), and personalized knowledge delivery to individual\\nemployees based on their speciﬁc needs and preferences(e.g., recommendations for speciﬁc training material).\\n4.4 Economics of Information SystemsGenerative AI will have signiﬁcant economic implications\\nacross various industries and markets. Generative AI canincrease efﬁciency and productivity by automating many\\ntasks that were previously performed by humans, such as\\ncontent creation, customer service, code generation, etc.This can reduce costs and open up new opportunities for\\ngrowth and innovation (Eloundou et al. 2023 ). Forexample, AI-based translation between different languages\\nis responsible for signiﬁcant economic gains (Brynjolfsson\\net al. 2019 ). The BISE community can contribute by pro-\\nviding quantiﬁcation through rigorous causal evidence.Given the velocity of AI research, it may be necessary to\\ntake a more abstract problem view instead of a concrete\\ntool view. For example, BISE research could run ﬁeldexperiments to compare programmers with and without AI\\nsupport and thereby assess whether generative AI systems\\nfor coding can improve the speed and quality of code\\ndevelopment. Similarly, researchers could test whether\\ngenerative AI will make artists more creative as they canmore easily create new content. A similar pattern was\\npreviously observed for AlphaGo, which has led humans to\\nbecome better players in the board game Go (Shin et al.2023 ).\\nGenerative AI is likely to transform the industry as a\\nwhole. This may hold true in the case of platforms thatmake user-generated content available (e.g., shutterstock.-\\ncom, pixabay.com, stackoverﬂow.com), which may be\\nreplaced by generative AI systems. Here, further researchquestions arise as to whether the use of generative AI can\\nlead to a competitive advantage and how generative AI\\nchanges competition. For example, what are the economicimplications if generative AI is developed as open-source\\nvs. closed-source systems? In this regard, a salient success\\nfactor for the development of conversational agents basedon generative AI (e.g., ChatGPT) are data from user\\ninteractions through dialogues and feedback on whether the\\ndialog was helpful. Hence, the value of such interactiondata is poorly understood and what it means if such data are\\nonly available to a few Big Tech companies.\\nThe digital transformation from generative AI also poses\\nchallenges and opportunities for economic policy. It may\\naffect future work patterns and, indirectly, worker capa-\\nbility via restructured learning mechanisms. It may alsoaffect content sharing and distribution and, hence, have\\nnon-trivial implications on the exploitation and protection\\nof intellectual properties. On top of that, a growing con-centration of power over AI innovation in the hands of a\\nfew companies may result in a monopoly of AI capabilities\\nand hamper future innovation, fair competition, scientiﬁcprogress, and thus welfare and human development at\\nlarge. All of these future impacts are important to under-\\nstand and provide meaningful directions for shaping eco-nomic policy.\\n4.5 Enterprise Modeling and Enterprise EngineeringEnterprise models are important artifacts for capturing\\ninsights into the core components and structures of anorganization, including business processes, resources,\\ninformation ﬂows, and IT systems (Vernadat 2020 ). A\\n123120 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.major drawback of traditional enterprise models is that they\\nare static and may not provide the level of abstraction that\\nis required by the end user. Likewise, their construction\\nand maintenance are time-consuming and expensive andrequire manual effort and human expertise (Silva et al.\\n2021 ). With generative AI, we see a large potential that\\nmany of these limitations can be addressed by generativeAI as assistive technology (Sandkuhl et al. 2018 ), for\\nexample by automatically creating and updating enterprise\\nmodels at different levels of abstraction or generating\\nmulti-modal representations.\\nFirst empirical results suggest that generative AI is able\\nto generate useful conceptual models based on textual\\nproblem descriptions. Fill et al. ( 2023 ) show that ER,\\nBPMN, UML, and Heraklit models can not only be gen-erated with very high to perfect accuracy from textual\\ndescriptions, but they also explored the interpretation of\\nexisting models and received good results. In the nearfuture, we expect more research that deals with the\\ndevelopment, evaluation, and application of more\\nadvanced approaches. Speciﬁcally, we expect that learnedrepresentations of enterprise models can be transformed\\ninto more application-speciﬁc formats and can either be\\nenriched with further details or reduced to the essentialcontent.\\nAgainst this background, the concept of ‘‘digital twins’’,\\nvirtual representations of enterprise assets, may experiencenew accentuation and extensions (Dietz and Pernul 2020 ).\\nEspecially, in the public sector, where most organizational\\nassets are non-tangible in the form of deﬁned services,speciﬁed procedures, legal texts, manuals, and organiza-\\ntional charts, generative AI can play a crucial role in dig-\\nitally mirroring and managing such assets along theirlifecycles. Similar beneﬁts could be explored with physical\\nassets in Industry 4.0 environments (Lasi et al. 2014 ).\\nIn enterprise engineering, the role of generative AI\\nsystems in existing as well as newly emerging IT land-\\nscapes to support the business goals and strategies of an\\norganization gives rise to numerous opportunities (e.g., inofﬁce solutions, customer relationship management and\\nbusiness analytics applications, knowledge management\\nsystems, etc.). Generative AI systems have the potential toevolve into core enterprise applications that can either be\\nhosted on-premise or rented in the cloud. Unsanctioned use\\nbears the risk that third-party applications will be used forjob-related tasks without explicit approval or even knowl-\\nedge of the organization. This phenomenon is commonly\\nknown as shadow IT and theories and frameworks havebeen proposed to explain this phenomenon, as well as\\nrecommending actions and policies to mitigate associated\\nrisks (cf. Haag and Eckhardt 2017 ; Klotz et al. 2022 ). In\\nthe light of generative AI, however, such approaches have\\nto be revisited for their applicability and effectiveness and,if necessary, need to be extended. Nevertheless, this situ-\\nation also offers the potential to explore and design new\\napproaches for more effective API management (e.g.,\\nincluding novel app store solutions, privacy and securitymechanisms, service level deﬁnitions, pricing, and licens-\\ning models) so that generative AI solutions can be\\nsmoothly integrated into existing enterprise IT infrastruc-tures without risking any unauthorized use and conﬁden-\\ntiality breaches.\\n4.6 Human Computer Interaction and Social\\nComputing\\nSalient behavioral questions related to the interactions\\nbetween humans and generative AI systems are stillunanswered. Examples are related to the perception,\\nacceptance, adoption, and trust of systems using generative\\nAI. A study found that news was believed less if generatedby generative AI instead of humans (Longoni et al. 2022 )\\nand another found that there is a replicant effect (Jakesch\\net al. 2019 ). Such behavior is likely to be context-speciﬁc\\nand will vary by other antecedents highlighting the need for\\na principled theoretical foundation to build successful\\ngenerative AI systems. The BISE community is wellpositioned to develop rigorous design recommendations.\\nFurther, generative AI is a key enabler for developing\\nhigh-quality interfaces for information systems based onnatural language that promote usability and accessibility.\\nFor example, such interfaces will not only make interac-\\ntions more intuitive but will also facilitate people withdisabilities. Generative AI is likely to increase the ‘‘degree\\nof intelligence’’ of user assistance systems. However, the\\ndesign of effective interactions must also be consideredwhen increasing the degree of intelligence (Maedche et al.\\n2016 ). Similarly, generative AI will undoubtedly have an\\nimpact on (computer-mediated) communication and col-laboration, such as within companies. For example, gen-\\nerative AI can create optimized content for social media,\\nemails, and reports. It can also help to improve theonboarding of new employees by creating personalized and\\ninteractive training materials. It can also enhance collabo-\\nration within teams by providing creative and intelligenceconservation agents that suggest, summarize, and synthe-\\nsize information based on the context of the team (e.g.,\\nautomated meeting notes).\\nSeveral applications and research opportunities are\\nrelated to the use of generative AI in marketing and,\\nespecially, e-commerce. It is expected that generative AIcan automate the creation of personalized marketing con-\\ntent, for instance, different sales slogans for introverts vs.\\nextroverts (Matz et al. 2017 ) or other personality traits as\\npersonalized marketing content is more effective than a\\none-content-ﬁts-all approach (Matz et al. 2023 ).\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 121\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Generative AI may automate various tasks in marketing\\nand media where content generation is needed (e.g., writing\\nnews stories, summarizing web pages for mobile devices,\\ncreating thumbnail images for news stories, translatingwritten news to audio for blind people and Braille-sup-\\nported formats for deaf people) that may be studied in\\nfuture research. Moreover, generative AI may be used inrecommender systems to boost the effectiveness of infor-\\nmation dissemination through personalization as content\\ncan be tailored better to the abilities of the recipient.\\nThe education sector is another example that will need\\nto reinvent in some parts following the availability ofconversational agents (Kasneci et al. 2023 ; Gimpel et al.\\n2023 ). At ﬁrst glance, generative AI seems to constitute an\\nunauthorized aid that jeopardizes student grading so farrelying on written examinations and term papers. However,\\nover time, examinations will adapt, and generative AI will\\nenable the development of comprehensive digital teachingassistants as well as the creation of supplemental teaching\\nmaterial such as teaching cases and recap questions. Fur-\\nther, the educator’s community will need to develop novelguidelines and governance frameworks that educate\\nlearners to rely appropriately on generative AI systems,\\nhow to verify model outputs, and to engineer promptsrather than the output itself.\\nIn addition, generative AI, speciﬁcally LLMs, can not\\nonly be used to spot harmful content on social media (e.g.,Maarouf et al. 2023 ), but it can also create realistic disin-\\nformation (e.g., fake news, propaganda) that is hard to\\ndetect by humans (Kreps et al. 2022 ; Jakesch et al. 2023 ).\\nNotwithstanding, AI-generated disinformation has previ-\\nously evolved as so-called deepfakes (Mirsky and Lee\\n2021 ), but recent advances in generative AI reduce the cost\\nof creating such disinformation and allow for unprece-\\ndented personalization. For example, generative AI can\\nautomatically adapt the tone and narrative of misinforma-tion to speciﬁc audiences that identify as extroverts or\\nintroverts, left- or right-wing partisans, or people with\\nparticular religious beliefs.\\nLastly, generative AI can facilitate—or even replace—\\ntraditional crowdsourcing where annotations or other\\nknowledge tasks are handled by a larger pool of crowdworkers, for example in social media content annotation\\n(Gilardi et al. 2023 ) or market research on willingness-to-\\npay for services and products (Brand et al. 2023 ). In gen-\\neral, we expect that generative AI will automate many\\nother tasks being a zero-shot / few-shot learner. However,\\nthis may also unfold negative implications: Users maycontribute less to question-answering forums such as\\nstackoverﬂow.com, which thus may reduce human-based\\nknowledge creation impairing the future performance ofAI-based question-answering systems that rely upon\\nhuman question-answering content for training. In a similarvein, the widespread availability of generative AI systems\\nmay also propel research around virtual assistants. Previ-\\nously, research made use of ‘‘Wizard-of-Oz’’ experiments\\n(Diederich et al. 2020 ), while future research may build\\nupon generative AI systems instead.\\nCrucially, automated content generation using genera-\\ntive AI is a new phenomenon, but automation in generaland how people are affected by automated systems has\\nbeen studied by scholars for decades. Thus, existing theo-\\nries on the interplay of humans with automated systems\\nmay be contextualized to generative AI systems.\\n4.7 Information Systems Engineering and Technology\\nGenerative AI offers many engineering- and technology-\\noriented research opportunities for the Information Systems\\ncommunity as a design-oriented discipline. This includes\\ndeveloping and evaluating design principles for generativeAI systems and applications to extend the limiting\\nboundaries of this technology (cf. Section 3). As such,\\ndesign principles can focus on how generative AI systemscan be made explainable to enable interpretability, under-\\nstanding, and trust; how they can be designed reliable to\\navoid discrimination effects or privacy issues; and howthey can be built more energy efﬁcient to promote envi-\\nronmental sustainability (cf. Schoormann et al. 2023b ).\\nWhile a lot of research is already being conducted intechnology-oriented disciplines such as computer science,\\nthe BISE community can add its strength by looking at\\ndesign aspects through a socio-technical lens, involvingindividuals, teams, organizations, and societal groups in\\ndesign activities, and thereby driving the ﬁeld forward with\\nnew insights from a human–machine perspective (Maedcheet al. 2019 ).\\nFurther, we see great potential that generative AI can be\\nleveraged to improve current practices in design scienceresearch projects when constructing novel IT artifacts (see\\nHevner et al. 2019 ). Here, one of the biggest potentials\\ncould lie in the support of knowledge retrieval tasks.Currently, design knowledge in the form of design\\nrequirements, design principles, and design features is\\noften only available in encapsulated written papers orimplicitly embedded in instantiated artifacts. Generative AI\\nhas the potential to extract such design knowledge that is\\nspread over a broad body of interdisciplinary research andmake it available in a collective form for scholars and\\npractitioners. This could also overcome the limitation that\\ndesign knowledge is currently rarely reused, which ham-pers the fundamental idea of knowledge accumulation in\\ndesign science research (Schoormann et al.\\n2021 ).\\nBesides engineering actual systems and applications, the\\nBISE community should also investigate how generative\\nAI can be used to support creativity-based tasks when\\n123122 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.initiating new design projects. In this regard, a promising\\ndirection could be to incorporate generative AI in design\\nthinking and similar methodologies to combine human\\ncreativity with computational creativity (Hawlitschek2023 ). This may support different phases and steps of\\ninnovation projects, such as idea generation, user needs\\nelicitation, prototyping, design evaluation, and designautomation, in which different types of generative AI\\nmodels and systems could be used and combined with each\\nother to form applications for creative industries (e.g.,\\ngenerated user stories with textual descriptions, visual\\nmock-ups for user interfaces, and quick software proto-types for proofs-of-concept). If generative AI is used to co-\\ncreate innovative outcomes, it may also enable better\\nreﬂection of the different design activities to ensure thenecessary learning (Schoormann et al. 2023a ).\\n5 Conclusion\\nGenerative AI is a branch of AI that can create new content\\nsuch as texts, images, or audio that increasingly often\\ncannot be distinguished anymore from human craftsman-\\nship. For this reason, generative AI has the potential totransform domains and industries that rely on creativity,\\ninnovation, and knowledge processing. In particular, it\\nenables new applications that were previously impossibleor impractical for automation, such as realistic virtual\\nassistants, personalized education and service, and digital\\nart. As such, generative AI has substantial implications forBISE practitioners and scholars as an interdisciplinary\\nresearch community. In our Catchword article, we offered\\na conceptualization of the principles of generative AI alonga model-, system-, and application-level view as well as a\\nsocial-technical view and described limitations of current\\ngenerative AI. Ultimately, we provided an impactfulresearch agenda for the BISE community and thereby\\nhighlight the manifold affordances that generative AI\\noffers through the lens of the BISE discipline.\\nAcknowledgements During the preparation of this Catchword, we\\ncontacted all current department editors at BISE to actively seek theirfeedback on our suggested directions. We gratefully acknowledge\\ntheir support.\\nFunding Open Access funding enabled and organized by Projekt\\nDEAL.\\nOpen Access This article is licensed under a Creative Commons\\nAttribution 4.0 International License, which permits use, sharing,\\nadaptation, distribution and reproduction in any medium or format, aslong as you give appropriate credit to the original author(s) and the\\nsource, provide a link to the Creative Commons licence, and indicate\\nif changes were made. The images or other third party material in thisarticle are included in the article’s Creative Commons licence, unlessindicated otherwise in a credit line to the material. If material is not\\nincluded in the article’s Creative Commons licence and your intended\\nuse is not permitted by statutory regulation or exceeds the permitteduse, you will need to obtain permission directly from the copyrightholder. To view a copy of this licence, visit http://creativecommons.\\norg/licenses/by/4.0/ .\\nReferences\\nAgostinelli A, Denk TI, Borsos Z, Engel J, Verzetti M, Caillon A,\\nHuang Q, Jansen A, Roberts A, Tagliasacchi M, et al (2023)\\nMusicLM: generating music from text. arXiv:2301.11325\\nAsatiani A, Malo P, Nagbøl PR, Penttinen E, Rinta-Kahila T,\\nSalovaara A (2021) Sociotechnical envelopment of artiﬁcial\\nintelligence: an approach to organizational deployment of\\ninscrutable artiﬁcial intelligence systems. J Assoc Inf Syst22(2):8\\nBaird A, Maruping LM (2021) The next generation of research on IS\\nuse: a theoretical framework of delegation to and from agentic IS\\nartifacts. MIS Q 45(1):315–341\\nBaron-Cohen S (1997) Mindblindness: an essay on autism and theory\\nof mind. MIT Press, Cambridge\\nBenlian A, Wiener M, Cram WA, Krasnova H, Maedche A,\\nMo¨hlmann M, Recker J, Remus U (2022) Algorithmic manage-\\nment. Bus Inf Syst Eng 64(6):825–839. https://doi.org/10.1007/\\ns12599-022-00764-w\\nBerente N, Gu B, Recker J, Santhanam R (2021) Special issue editor’s\\ncomments: managing artiﬁcial intelligence. MIS Q45(3):1433–1450\\nBeverungen D, Buijs JCAM, Becker J, Di Ciccio C, van der Aalst\\nWMP, Bartelheimer C, vom Brocke J, Comuzzi M, Kraume K,Leopold H, Matzner M, Mendling J, Ogonek N, Post T, ResinasM, Revoredo K, del Rı ´o-Ortega A, La Rosa M, Santoro FM,\\nSolti A, Song M, Stein A, Stierle M, Wolf V (2021) Seven\\nparadoxes of business process management in a hyper-connectedworld. Bus Inf Syst Eng 63(2):145–156. https://doi.org/10.1007/\\ns12599-020-00646-z\\nBirhane A, Prabhu VU, Kahembwe E (2021) Multimodal datasets:\\nmisogyny, pornography, and malignant stereotypes. arXiv:2110.\\n01963\\nBishop C (2006) Pattern recognition and machine learning. Springer,\\nNew York\\nBommasani R, Hudson DA, Adeli E, Altman R, Arora S, von Arx S,\\nBernstein MS, Bohg J, Bosselut A, Brunskill E, Brynjolfsson E,\\nBuch S, Card D, Castellon R, Chatterji NS, Chen AS, Creel KA,\\nDavis J, Demszky D, Donahue C, Doumbouya M, Durmus E,Ermon S, Etchemendy J, Ethayarajh K, Fei-Fei L, Finn C, GaleT, Gillespie LE, Goel K, Goodman ND, Grossman S, Guha N,\\nHashimoto T, Henderson P, Hewitt J, Ho DE, Hong J, Hsu K,\\nHuang J, Icard TF, Jain S, Jurafsky D, Kalluri P, Karamcheti S,Keeling G, Khani F, Khattab O, Koh PW, Krass MS, Krishna R,\\nKuditipudi R, Kumar A, Ladhak F, Lee M, Lee T, Leskovec J,\\nLevent I, Li XL, Li X, Ma T, Malik A, Manning CD,Mirchandani SP, Mitchell E, Munyikwa Z, Nair S, Narayan A,Narayanan D, Newman B, Nie A, Niebles JC, Nilforoshan H,\\nNyarko JF, Ogut G, Orr L, Papadimitriou I, Park JS, Piech C,\\nPortelance E, Potts C, Raghunathan A, Reich R, Ren H, Rong F,Roohani YH, Ruiz C, Ryan J, R’e C, Sadigh D, Sagawa S,Santhanam K, Shih A, Srinivasan KP, Tamkin A, Taori R,\\nThomas AW, Trame `r F, Wang RE, Wang W, Wu B, Wu J, Wu\\nY, Xie SM, Yasunaga M, You J, Zaharia MA, Zhang M, ZhangT, Zhang X, Zhang Y, Zheng L, Zhou K, Liang P (2021) On the\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 123\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.opportunities and risks of foundation models. arXiv:2108.\\n07258https://doi.org/10.48550/arXiv.2108.07258\\nBrand J, Israeli A, Ngwe D (2023) Using GPT for market research.\\nSSRN 4395751\\nBrown T, Mann B, Ryder N, Subbiah M, Kaplan JD, Dhariwal P,\\nNeelakantan A, Shyam P, Sastry G, Askell A et al (2020)Language models are few-shot learners. Adv Neural Inf ProcessSyst 33:1877–1901\\nBrynjolfsson E, Hui X, Liu M (2019) Does machine translation affect\\ninternational trade? Evidence from a large digital platform.Manag Sci 65(12):5449–5460\\nBurger B, Kanbach DK, Kraus S, Breier M, Corvello V (2023) On the\\nuse of AI-based tools like ChatGPT to support management\\nresearch. Europ J Innov Manag 26(7):233–241. https://doi.org/\\n10.1108/EJIM-02-2023-0156\\nBusch K, Rochlitzer1 A, Sola D, Leopold H (2023) Just tell me:\\nPrompt engineering in business process management. arXiv:\\n2304.07183\\nCaliskan A, Bryson JJ, Narayanan A (2017) Semantics derived\\nautomatically from language corpora contain human-like biases.\\nSci 356(6334):183–186\\nCameron L, Lamers L, Leicht-Deobald U, Lutz C, Meijerink J,\\nMo¨hlmann M (2023) Algorithmic management: its implications\\nfor information systems research. Commun AIS 52(1):518–537.\\nhttps://doi.org/10.17705/1CAIS.05221\\nCarlson SM, Koenig MA, Harms MB (2013) Theory of mind. WIREs\\nCogn Sci 4:391–402\\nC¸ elikok MM, Peltola T, Daee P, Kaski S (2019) Interactive AI with a\\ntheory of mind. In: ACM CHI 2019 workshop: computationalmodeling in human-computer interaction, vol 80, pp 4215–4224\\nChen L, Zaharia M, Zou J (2023) How is chatgpt’s behavior changing\\nover time? arXiv:2307.09009\\nChen M, Tworek J, Jun H, Yuan Q, Pinto HPdO, Kaplan J, Edwards\\nH, Burda Y, Joseph N, Brockman G, et al (2021) Evaluating\\nlarge language models trained on code. arXiv:2107.03374\\nChiang T (2023) ChatGPT is a blurry JPEG of the web. https://www.\\nnewyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web , accessed 25 Aug 2023\\nDavison RM, Laumer S, Tarafdar M, Wong LHM (2023) ISJ\\neditorial: pickled eggs: generative AI as research assistant or co-author? Inf Syst J Early View. https://doi.org/10.1111/isj.12455\\nDe-Arteaga M, Feuerriegel S, Saar-Tsechansky M (2022) Algorith-\\nmic fairness in business analytics: directions for research and\\npractice. Prod Oper Manag 31(10):3749–3770\\nDebortoli S, Mu ¨ller O, vom Brocke J (2014) Comparing business\\nintelligence and big data skills. Bus Inf Syst Eng 6(5):289–300.\\nhttps://doi.org/10.1007/s12599-014-0344-2\\nDellermann D, Ebel P, So ¨llner M, Leimeister JM (2019) Hybrid\\nintelligence. Bus Inf Syst Eng 61(5):637–643. https://doi.org/10.\\n1007/s12599-019-00595-2\\nDevlin J, Chang MW, Lee K, Toutanova K (2018) BERT: Pre-\\ntraining of deep bidirectional transformers for language under-standing. arXiv:1810.04805\\nDiederich S, Brendel AB, Kolbe LM (2020) Designing anthropo-\\nmorphic enterprise conversational agents. Bus Inf Syst Eng62(3):193–209\\nDietz M, Pernul G (2020) Digital twin: empowering enterprises\\ntowards a system-of-systems approach. Bus Inf Syst Eng62(2):179–184. https://doi.org/10.1007/s12599-019-00624-0\\nDolata M, Feuerriegel S, Schwabe G (2022) A sociotechnical view of\\nalgorithmic fairness. Inf Syst J 32(4):754–818\\nvan Dun C, Moder L, Kratsch W, Ro ¨glinger M (2023) ProcessGAN:\\nsupporting the creation of business process improvement ideasthrough generative machine learning. Decis Support Syst\\n165(113):880. https://doi.org/10.1016/j.dss.2022.113880Dwivedi YK, Kshetri N, Hughes L, Slade EL, Jeyaraj A, Kar AK,\\nBaabdullah AM, Koohang A, Raghavan V, Ahuja M et al (2023)\\n‘‘So what if ChatGPT wrote it?’’ Multidisciplinary perspectiveson opportunities, challenges and implications of generative\\nconversational AI for research, practice and policy. Int J Inf\\nManag 71(102):642\\nEloundou T, Manning S, Mishkin P, Rock D (2023) GPTs are GPTs:\\nan early look at the labor market impact potential of large\\nlanguage models. arxiv:2303.10130 , accessed 03 April 2023\\nEskreis-Winkler L, Fishbach A (2022) Surprised elaboration: when\\nwhite men get longer sentences. J Personal Soc Psychol123:941–956\\nFerrara E (2023) Should ChatGPT be biased? Challenges and risks of\\nbias in large language models. arXiv:2304.03738\\nFeuerriegel S, Dolata M, Schwabe G (2020) Fair AI: challenges and\\nopportunities. Bus Inf Syst Eng 62:379–384\\nFeuerriegel S, Shrestha YR, von Krogh G, Zhang C (2022) Bringing\\nartiﬁcial intelligence to business management. Nat MachineIntell 4(7):611–613\\nFill HG, Fettke P, Ko ¨pke J (2023) Conceptual modeling and large\\nlanguage models: impressions from ﬁrst experiments withChatGPT. EMISAJ 18(3):1–15. https://doi.org/10.18417/emisa.\\n18.3\\nGanguli D, Askell A, Schiefer N, Liao T, Lukos ˇiu¯t_e K, Chen A,\\nGoldie A, Mirhoseini A, Olsson C, Hernandez D, et al (2023)The capacity for moral self-correction in large language models.arXiv:2302.07459\\nGarcia T (2023) David Guetta replicated Eminem’s voice in a song\\nusing artiﬁcial intelligence. https://variety.com/2023/music/\\nnews/david-guetta-eminem-artiﬁcial-intelligence-1235516924/ ,\\naccessed 25 Aug 2023\\nGilardi F, Alizadeh M, Kubli M (2023) ChatGPT outperforms crowd-\\nworkers for text-annotation tasks. arXiv:2303.15056\\nGimpel H, Hall K, Decker S, Eymann T, La ¨mmermann L, Ma ¨dche A,\\nRo¨glinger M, Ruiner C, Schoch M, Schoop M, et al (2023)\\nUnlocking the power of generative ai models and systems suchas GPT-4 and ChatGPT for higher education. https://digital.uni-\\nhohenheim.de/ﬁleadmin/einrichtungen/digital/Generative_AI_\\nand_ChatGPT_in_Higher_Education.pdf , accessed 25 Aug 2023\\nGoldman Sachs (2023) Generative AI could raise global GDP by 7%.\\nhttps://www.goldmansachs.com/insights/pages/generative-ai-could-raise-global-gdp-by-7-percent.html\\nGoodfellow I, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley D,\\nOzair S, Courville A, Bengio Y (2014) Generative adversarialnets. Adv Neural Inf Process Syst 27:2672–2680\\nGray HM, Gray K, Wegner DM (2007) Dimensions of mind\\nperception. Sci 315(5812):619–619\\nGrisold T, Groß S, Stelzl K, vom Brocke J, Mendling J, Ro ¨glinger M,\\nRosemann M (2022) The ﬁve diamond method for explorative\\nbusiness process management. Bus Inf Syst Eng 64(2):149–166.\\nhttps://doi.org/10.1007/s12599-021-00703-1\\nHaag S, Eckhardt A (2017) Shadow IT. Bus Inf Syst Eng\\n59(6):469–473. https://doi.org/10.1007/s12599-017-0497-x\\nHaase J, Hanel PHP (2023) Artiﬁcial muses: generative artiﬁcial\\nintelligence chatbots have risen to human-level creativity. arXiv:\\n2303.12003\\nHartmann J, Bergner A, Hildebrand C (2023a) MindMiner: uncov-\\nering linguistic markers of mind perception as a new lens tounderstand consumer-smart object relationships. J Consum Psy-chol. https://doi.org/10.1002/jcpy.1381\\nHartmann J, Schwenzow J, Witte M (2023b) The political ideology of\\nconversational AI: converging evidence on ChatGPT’s pro-environmental, left-libertarian orientation. arXiv:2301.01768\\nHawlitschek F (2023) Interview with Samuel Tschepe on ‘‘Quo vadis\\ndesign thinking?’’. Bus Inf Syst Eng 65(2):223–228. https://doi.\\norg/10.1007/s12599-023-00792-0\\n123124 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Herm LV, Janiesch C, Reijers HA, Seubert F (2021) From symbolic\\nRPA to intelligent RPA: challenges for developing and operating\\nintelligent software robots. In: International conference onbusiness process management, pp 289–305\\nHevner A, vom Brocke J, Maedche A (2019) Roles of digital\\ninnovation in design science research. Bus Inf Syst Eng61(1):3–8. https://doi.org/10.1007/s12599-018-0571-z\\nHo J, Jain A, Abbeel P (2020) Denoising diffusion probabilistic\\nmodels. Adv Neural Inf Process Syst 33:6840–6851\\nJakesch M, French M, Ma X, Hancock JT, Naaman M (2019) AI-\\nmediated communication: how the perception that proﬁle textwas written by AI affects trustworthiness. In: Conference on\\nhuman factors in computing systems (CHI)\\nJakesch M, Hancock JT, Naaman M (2023) Human heuristics for AI-\\ngenerated language are ﬂawed. Proc Natl Acad Sci120(11):e2208839\\nJaniesch C, Zschech P, Heinrich K (2021) Machine learning and deep\\nlearning. Electron Market 31(3):685–695. https://doi.org/10.\\n1007/s12525-021-00475-2\\nJi Z, Lee N, Frieske R, Yu T, Su D, Xu Y, Ishii E, Bang YJ, Madotto\\nA, Fung P (2023) Survey of hallucination in natural languagegeneration. ACM Comput Surv 55(12):1–38\\nKasneci E, Seßler K, Ku ¨chemann S, Bannert M, Dementieva D,\\nFischer F, Gasser U, Groh G, Gu ¨nnemann S, Hu ¨llermeier E et al\\n(2023) ChatGPT for good? On opportunities and challenges oflarge language models for education. Learn Individ Differ103(102):274\\nKecht C, Egger A, Kratsch W, Ro ¨glinger M (2023) Quantifying\\nchatbots’ ability to learn business processes. Inf Syst113(102):176. https://doi.org/10.1016/j.is.2023.102176\\nKhan J (2021) AI’s carbon footprint is big, but easy to reduce, Google\\nresearchers say. Fortune\\nKingma DP, Welling M (2013) Auto-encoding variational Bayes.\\nhttps://doi.org/10.48550/arXiv.1312.6114\\nKlotz S, Westner M, Strahringer S (2022) Critical success factors of\\nbusiness-managed IT: it takes two to tango. Inf Syst Manag39(3):220–240\\nKraus M, Feuerriegel S, Oztekin A (2020) Deep learning in business\\nanalytics and operations research: models, applications and\\nmanagerial implications. Europ J Oper Res 281(3):628–641.https://doi.org/10.1016/j.ejor.2019.09.018\\nKreps S, McCain RM, Brundage M (2022) All the news that’s ﬁt to\\nfabricate: AI-generated text as a tool of media misinformation.\\nJ Exp Polit Sci 9(1):104–117\\nKru¨gel S, Ostermaier A, Uhl M (2023) ChatGPT’s inconsistent moral\\nadvice inﬂuences users’ judgment. Sci Report 13(1):4569\\nLasi H, Fettke P, Kemper HG, Feld T, Hoffmann M (2014) Industry\\n4.0. Bus Inf Syst Eng 6(4):239–242. https://doi.org/10.1007/\\ns12599-014-0334-4\\nLi Y, Choi D, Chung J, Kushman N, Schrittwieser J, Leblond R,\\nEccles T, Keeling J, Gimeno F, Dal Lago A et al (2022)Competition-level code generation with alphacode. Science378(6624):1092–1097\\nLiu P, Yuan W, Fu J, Jiang Z, Hayashi H, Neubig G (2023) Pre-train,\\nprompt, and predict: a systematic survey of prompting methodsin natural language processing. ACM Comput Surv 55(9):1–35\\nLongoni C, Fradkin A, Cian L, Pennycook G (2022) News from\\ngenerative artiﬁcial intelligence is believed less. In: ACMconference on fairness, accountability, and transparency(FAccT), pp 97–106\\nMaarouf A, Ba ¨r D, Geissler D, Feuerriegel S (2023) HQP: a human-\\nannotated dataset for detecting online propaganda. arXiv:2304.\\n14931\\nMaedche A, Morana S, Schacht S, Werth D, Krumeich J (2016)\\nAdvanced user assistance systems. Bus Inf Syst Eng 58:367–370Maedche A, Legner C, Benlian A, Berger B, Gimpel H, Hess T, Hinz\\nO, Morana S, So ¨llner M (2019) AI-based digital assistants:\\nopportunities, threats, and research perspectives. Bus Inf SystEng 61(4):535–544. https://doi.org/10.1007/s12599-019-00600-\\n8\\nMatz S, Teeny J, Vaid SS, Harari GM, Cerf M (2023) The potential of\\ngenerative AI for personalized persuasion at scale. PsyArXiv\\nMatz SC, Kosinski M, Nave G, Stillwell DJ (2017) Psychological\\ntargeting as an effective approach to digital mass persuasion.\\nProc Natl Acad Sci 114(48):12,714-12,719\\nMetz C (2023) Instant videos could represent the next leap in A.I.\\ntechnology. https://www.nytimes.com/2023/04/04/technology/\\nrunway-ai-videos.html , accessed 25 Aug 2023\\nMirsky Y, Lee W (2021) The creation and detection of deepfakes: a\\nsurvey. ACM Comput Survey 54(1):1–41\\nMorana S, Maedche A, Schacht S (2019) Designing process guidance\\nsystems. J Assoc Inf Syst pp 499–535, https://doi.org/10.17705/\\n1jais.00542\\nNg A, Jordan M (2001) On discriminative vs. generative classiﬁers: a\\ncomparison of logistic regression and naive Bayes. In: Advances\\nin Neural Information Processing Systems, vol 14, pp 841–848,https://papers.nips.cc/paper_ﬁles/paper/2001/hash/7b7a53e239400a13bd6be6c91c4f6c4e-Abstract.html , accessed\\n25 Aug 2023\\nOpenAI (2022) Introducing ChatGPT. https://openai.com/blog/\\nchatgpt , accessed 25 Aug 2023\\nOpenAI (2023a) GPT-4 technical report. arXiv:2303.08774\\nOpenAI (2023b) How should AI systems behave, and who should\\ndecide? https://openai.com/blog/how-should-ai-systems-behave ,\\naccessed 25 Aug 2023\\nPark JS, O’Brien JC, Cai CJ, Morris MR, Liang P, Bernstein MS\\n(2023) Generative agents: interactive simulacra of humanbehavior. arXiv:2304.03442\\nPeres R, Schreier M, Schweidel D, Sorescu A (2023) On ChatGPT\\nand beyond: how generative artiﬁcial intelligence may affect\\nresearch, teaching, and practice. Int J Res Market 40:269–275\\nRabinowitz NC, Perbet F, Song HF, Zhang C, Eslami SMA,\\nBotvinick MM (2018) Machine theory of mind. In: International\\nconference on machine learning, PMLR, vol 80, pp 4215–4224,\\nhttp://proceedings.mlr.press/v80/rabinowitz18a.html , accessed\\n25 Aug 2023\\nRai A (2020) Explainable AI: from black box to glass box. J Acad\\nMarket Sci 48:137–141\\nRamaswamy V, Ozcan K (2018) What is co-creation? An interac-\\ntional creation framework and its implications for value creation.\\nJ Bus Res 84:196–205\\nReisenbichler M, Reutterer T, Schweidel DA, Dan D (2022)\\nFrontiers: supporting content marketing with natural languagegeneration. Market Sci 41(3):441–452\\nRombach R, Blattmann A, Lorenz D, Esser P, Ommer B (2022) High-\\nresolution image synthesis with latent diffusion models. In:IEEE/CVF conference on computer vision and pattern recogni-tion, pp 10684–10695\\nSandkuhl K, Fill H, Hoppenbrouwers S, Krogstie J, Matthes F,\\nOpdahl AL, Schwabe G, Uludag O ¨, Winter R (2018) From\\nexpert discipline to common practice: a vision and research\\nagenda for extending the reach of enterprise modeling. Bus Inf\\nSyst Eng 60(1):69–80. https://doi.org/10.1007/s12599-017-0516-\\ny\\nSchoormann T, Mo ¨ller F, Hansen MRP (2021) How do researchers\\n(re-)use design principles: An inductive analysis of cumulative\\nresearch. In: The Next Wave of Sociotechnical Design, Springer,Cham, Lecture Notes in Computer Science, pp 188–194, https://\\ndoi.org/10.1007/978-3-030-82405-1_20\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 125\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Schoormann T, Stadtla ¨nder M, Knackstedt R (2023) Act and reﬂect:\\nintegrating reﬂection into design thinking. J Manag Inf Syst\\n40(1):7–37. https://doi.org/10.1080/07421222.2023.2172773\\nSchoormann T, Strobel G, Mo ¨ller F, Petrik D, Zschech P (2023)\\nArtiﬁcial intelligence for sustainability: a systematic review of\\ninformation systems literature. Commun AIS 52(1):8\\nSchramowski P, Turan C, Andersen N, Rothkopf CA, Kersting K\\n(2022) Large pre-trained language models contain human-like\\nbiases of what is right and wrong to do. Nat Machine Intell\\n4(3):258–268\\nSchwartz R, Dodge J, Smith NA, Etzioni O (2020) Green AI.\\nCommun ACM 63(12):54–63\\nScho¨bel S, Schmitt A, Benner D, Saqr M, Janson A, Leimeister JM\\n(2023) Charting the evolution and future of conversationalagents: a research agenda along ﬁve waves and new frontiers. InfSyst Front. https://doi.org/10.1007/s10796-023-10375-9\\nSenoner J, Netland T, Feuerriegel S (2022) Using explainable\\nartiﬁcial intelligence to improve process quality: evidence fromsemiconductor manufacturing. Manag Sci 68(8):5704–5723\\nShin M, Kim J, van Opheusden B, Grifﬁths TL (2023) Superhuman\\nartiﬁcial intelligence can improve human decision-making byincreasing novelty. Proc Natl Acad Sci 120(12):e2214840,120\\nShollo A, Hopf K, Thiess T, Mu ¨ller O (2022) Shifting ML value\\ncreation mechanisms: a process model of ML value creation.\\nJ Strateg Inf Syst 31(3):101,734. https://doi.org/10.1016/j.jsis.\\n2022.101734\\nSiebers P, Janiesch C, Zschech P (2022) A survey of text represen-\\ntation methods and their genealogy. IEEE Access 10:96,492-\\n96,513. https://doi.org/10.1109/ACCESS.2022.3205719\\nSilva N, Sousa P, Mira da Silva M (2021) Maintenance of enterprise\\narchitecture models. Bus Inf Syst Eng 63(2):157–180. https://doi.\\norg/10.1007/s12599-020-00636-1\\nSlack D, Krishna S, Lakkaraju H, Singh S (2023) Explaining machine\\nlearning models with interactive natural language conversations\\nusing TalkToModel. Nat Machine Intell 5:873–883\\nSmits J, Borghuis T (2022) Generative AI and intellectual property\\nrights. Law and artiﬁcial intelligence: regulating AI and applyingai in legal practice. Springer, Heidelberg, pp 323–344\\nSpitale G, Biller-Andorno N, Germani F (2023) AI model GPT-3 (dis)\\ninforms us better than humans. Sci Adv 9:eadh1850\\nStrobelt H, Webson A, Sanh V, Hoover B, Beyer J, Pﬁster H, Rush\\nAM (2023) Interactive and visual prompt engineering for ad-hoc\\ntask adaptation with large language models. IEEE Transact\\nVisual Comput Graphics 29(1):1146–1156. https://doi.org/10.\\n1109/TVCG.2022.3209479Susarla A, Thatcher RGJB, Sarker S (2023) Editorial: the janus effect\\nof generative AI: charting the path for responsible conduct of\\nscholarly activities in information systems. Inf Syst Res34(2):399–408. https://doi.org/10.1287/isre.2023.ed.v34.n2\\nSutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning\\nwith neural networks. Adv Neural Inf Process Syst27:3104–3112\\nTeubner T, Flath CM, Weinhardt C, van der Aalst W, Hinz O (2023)\\nWelcome to the era of ChatGPT. Bus Inf Syst Eng 65(2):95–101.\\nhttps://doi.org/10.1007/s12599-023-00795-x\\nUnsal S, Atas H, Albayrak M, Turhan K, Acar AC, Dog ˘an T (2022)\\nLearning functional properties of proteins with language models.\\nNat Machine Intell 4(3):227–245\\nvan der Aalst WMP, Bichler M, Heinzl A (2018) Robotic process\\nautomation. Bus Inf Syst Eng 60(4):269–272. https://doi.org/10.\\n1007/s12599-018-0542-4\\nVaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN,\\nKaiser Ł, Polosukhin I (2017) Attention is all you need. AdvNeural Inf Process Syst 30:6000–6010\\nVernadat F (2020) Enterprise modelling: research review and outlook.\\nComput Indust 122(103):265. https://doi.org/10.1016/j.compind.\\n2020.103265\\nVidgof M, Bachhofner S, Mendling J (2023) Large language models\\nfor business process management: opportunities and challenges.\\nIn: Business process management forum. Lecture Notes inComputer Science, Springer, Cham, pp 107-123\\nvon Zahn M, Feuerriegel S, Kuehl N (2022) The cost of fairness in\\nAI: evidence from e-commerce. Bus Inf Syst Eng 64:335–348\\nWolfe R, Banaji MR, Caliskan A (2022) Evidence for hypodescent in\\nvisual semantic AI. In: ACM conference on fairness, account-\\nability, and transparency, pp 1293–1304\\nZiegler DM, Stiennon N, Wu J, Brown TB, Radford A, Amodei D,\\nChristiano P, Irving G (2019) Fine-tuning language models fromhuman preferences. arXiv:1909.08593\\nZilker S, Weinzierl S, Zschech P, Kraus M, Matzner M (2023) Best of\\nboth worlds: combining predictive power with interpretable andexplainable results for patient pathway prediction. In: Proceed-ings of the 31st European Conference on Information Systems\\n(ECIS), Kristiansand, Norway\\nZschech P, Horn R, Ho ¨schele D, Janiesch C, Heinrich K (2020)\\nIntelligent user assistance for automated data mining methodselection. Bus Inf Syst Eng 62(3):227–247. https://doi.org/10.\\n1007/s12599-020-00642-3\\n123126 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.1.\\n2.\\n3.\\n4.\\n5.\\n6.Terms and Conditions \\nSpringer Nature journal content, brought to you courtesy of Springer Nature Customer Service Center GmbH (“Springer Nature”). \\nSpringer Nature supports a reasonable amount of sharing of  research papers by authors, subscribers and authorised users (“Users”), for small-\\nscale personal, non-commercial use provided that all copyright, trade and service marks and other proprietary notices are maintained. By\\naccessing, sharing, receiving or otherwise using the Springer Nature journal content you agree to these terms of use (“Terms”). For these\\npurposes, Springer Nature considers academic use (by researchers and students) to be non-commercial. \\nThese Terms are supplementary and will apply in addition to any applicable website terms and conditions, a relevant site licence or a personal\\nsubscription. These Terms will prevail over any conflict or ambiguity with regards to the relevant terms, a site licence or a personal subscription\\n(to the extent of the conflict or ambiguity only). For Creative Commons-licensed articles, the terms of the Creative Commons license used will\\napply. \\nWe collect and use personal data to provide access to the Springer Nature journal content. We may also use these personal data internally within\\nResearchGate and Springer Nature and as agreed share it, in an anonymised way, for purposes of tracking, analysis and reporting. We will not\\notherwise disclose your personal data outside the ResearchGate or the Springer Nature group of companies unless we have your permission as\\ndetailed in the Privacy Policy. \\nWhile Users may use the Springer Nature journal content for small scale, personal non-commercial use, it is important to note that Users may\\nnot:  \\nuse such content for the purpose of providing other users with access on a regular or large scale basis or as a means to circumvent access\\ncontrol;\\nuse such content where to do so would be considered a criminal or statutory offence in any jurisdiction, or gives rise to civil liability, or is\\notherwise unlawful;\\nfalsely or misleadingly imply or suggest endorsement, approval , sponsorship, or association unless explicitly agreed to by Springer Nature in\\nwriting;\\nuse bots or other automated methods to access the content or redirect messages\\noverride any security feature or exclusionary protocol; or\\nshare the content in order to create substitute for Springer Nature products or services or a systematic database of Springer Nature journal\\ncontent. \\nIn line with the restriction against commercial use, Springer Nature does not permit the creation of a product or service that creates revenue,\\nroyalties, rent or income from our content or its inclusion as part of a paid for service or for other commercial gain. Springer Nature journal\\ncontent cannot be used for inter-library loans and librarians may not upload Springer Nature journal content on a large scale into their, or any\\nother, institutional repository. \\nThese terms of use are reviewed regularly and may be amended at any time. Springer Nature is not obligated to publish any information or\\ncontent on this website and may remove it or features or functionality at our sole discretion, at any time with or without notice. Springer Nature\\nmay revoke this licence to you at any time and remove access to any copies of the Springer Nature journal content which have been saved. \\nTo the fullest extent permitted by law, Springer Nature makes no warranties, representations or guarantees to Users, either express or implied\\nwith respect to the Springer nature journal content and all parties disclaim and waive any implied warranties or warranties imposed by law,\\nincluding merchantability or fitness for any particular purpose. \\nPlease note that these rights do not automatically extend to content, data or other material published by Springer Nature that may be licensed\\nfrom third parties. \\nIf you would like to use or distribute our Springer Nature journal content to a wider audience or on a regular basis or in any other manner not\\nexpressly permitted by these Terms, please contact Springer Nature at  \\nonlineservice@springernature.com '"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee116f0-1033-45c6-87eb-4cc5554fbe88",
   "metadata": {},
   "source": [
    "### Initializing connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7790d39f-3a81-4e7c-991b-2072abb63148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:24.288840Z",
     "start_time": "2024-04-26T14:28:18.703390Z"
    }
   },
   "outputs": [],
   "source": [
    "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813a1d82-89e1-4a52-9615-bc032a5cd5d6",
   "metadata": {},
   "source": [
    "### Create the LangChain embedding and LLM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7ce083c-60b0-4573-88af-1f7933a65059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:26.402359Z",
     "start_time": "2024-04-26T14:28:26.309172Z"
    }
   },
   "outputs": [],
   "source": [
    "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdfdf7-d21f-4ba1-a0f4-0a08b21f41e7",
   "metadata": {},
   "source": [
    "### Create your LangChain vector store (backed by Astra DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da470d04-2b92-41c6-968b-967be379f760",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:33.088178Z",
     "start_time": "2024-04-26T14:28:32.337150Z"
    }
   },
   "outputs": [],
   "source": [
    "astra_vector_store = Cassandra(\n",
    "    embedding=embedding,\n",
    "    table_name=\"qa_mini_demo\",\n",
    "    session=None,\n",
    "    keyspace=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6476cb64-48ff-4cc3-8948-5ece87866f6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:33.825336Z",
     "start_time": "2024-04-26T14:28:33.818546Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "810c61ab-3e96-4170-aef1-130c67965e54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:38.811518Z",
     "start_time": "2024-04-26T14:28:38.768926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['CATCHWORD\\nGenerative AI\\nStefan Feuerriegel •Jochen Hartmann •Christian Janiesch •\\nPatrick Zschech\\nReceived: 29 April 2023 / Accepted: 7 August 2023 / Published online: 12 September 2023\\n/C211The Author(s) 2023\\nKeywords Generative AI /C1Artiﬁcial intelligence /C1\\nDecision support /C1Content creation /C1Information systems\\n1 Introduction\\nTom Freston is credited with saying ‘‘Innovation is taking\\ntwo things that exist and putting them together in a new\\nway’’. For a long time in history, it has been the prevailingassumption that artistic, creative tasks such as writing\\npoems, creating software, designing fashion, and compos-\\ning songs could only be performed by humans. Thisassumption has changed drastically with recent advances in\\nartiﬁcial intelligence (AI) that can generate new content in',\n 'ing songs could only be performed by humans. Thisassumption has changed drastically with recent advances in\\nartiﬁcial intelligence (AI) that can generate new content in\\nways that cannot be distinguished anymore from humancraftsmanship.The term generative AI refers to computational tech-\\nniques that are capable of generating seemingly new,\\nmeaningful content such as text, images, or audio fromtraining data. The widespread diffusion of this technology\\nwith examples such as Dall-E 2, GPT-4, and Copilot is\\ncurrently revolutionizing the way we work and communi-cate with each other. Generative AI systems can not only\\nbe used for artistic purposes to create new text mimicking\\nwriters or new images mimicking illustrators, but they canand will assist humans as intelligent question-answering',\n 'be used for artistic purposes to create new text mimicking\\nwriters or new images mimicking illustrators, but they canand will assist humans as intelligent question-answering\\nsystems. Here, applications include information technology\\n(IT) help desks where generative AI supports transitionalknowledge work tasks and mundane needs such as cooking\\nrecipes and medical advice. Industry reports suggest that\\ngenerative AI could raise global gross domestic product(GDP) by 7% and replace 300 million jobs of knowledge\\nworkers (Goldman Sachs 2023 ). Undoubtedly, this has\\ndrastic implications not only for the Business & Informa-tion Systems Engineering (BISE) community, where we\\nwill face revolutionary opportunities, but also challenges\\nand risks that we need to tackle and manage to steer the',\n 'will face revolutionary opportunities, but also challenges\\nand risks that we need to tackle and manage to steer the\\ntechnology and its use in a responsible and sustainable\\ndirection.\\nIn this Catchword article, we provide a conceptualiza-\\ntion of generative AI as an entity in socio-technical systems\\nand provide examples of models, systems, and applica-tions. Based on that, we introduce limitations of current\\ngenerative AI and provide an agenda for BISE research.\\nPrevious papers discuss generative AI around speciﬁcmethods such as language models (e.g., Teubner et al.\\n2023 ; Dwivedi et al. 2023 ; Scho ¨bel et al. 2023 ) or speciﬁc\\napplications such as marketing (e.g., Peres et al. 2023 ),\\ninnovation management (Burger et al. 2023 ), scholarly',\n '2023 ; Dwivedi et al. 2023 ; Scho ¨bel et al. 2023 ) or speciﬁc\\napplications such as marketing (e.g., Peres et al. 2023 ),\\ninnovation management (Burger et al. 2023 ), scholarly\\nresearch (e.g., Susarla et al. 2023 ; Davison et al. 2023 ),\\nand education (e.g., Kasneci et al. 2023 ; Gimpel et al.Accepted after one revision by Susanne Strahringer.\\nS. Feuerriegel ( &)\\nLMU Munich and Munich Center for Machine Learning,\\nGeschwister-Scholl-Platz 1, 80539 Munich, Germanye-mail: feuerriegel@lmu.de\\nJ. Hartmann\\nTechnical University of Munich, TUM School of Management,Arcisstr. 21, 80333 Munich, Germanye-mail: jochen.hartmann@tum.de\\nC. Janiesch\\nTU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund,Germanye-mail: christian.janiesch@tu-dortmund.de\\nP. Zschech',\n 'C. Janiesch\\nTU Dortmund University, Otto-Hahn-Str. 12, 44319 Dortmund,Germanye-mail: christian.janiesch@tu-dortmund.de\\nP. Zschech\\nFAU Erlangen-Nu ¨rnberg, Lange Gasse 20, 90403 Nu ¨rnberg,\\nGermanye-mail: patrick.zschech@fau.de\\n123Bus Inf Syst Eng 66(1):111–126 (2024)\\nhttps://doi.org/10.1007/s12599-023-00834-7\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.2023 ). Different from these works, we focus on generative\\nAI in the context of information systems, and, to this end,\\nwe discuss several opportunities and challenges that are\\nunique to the BISE community and make suggestions forimpactful directions for BISE research.\\n2 Conceptualization\\n2.1 Mathematical Principles of Generative AIGenerative AI is primarily based on generative modeling,',\n '2 Conceptualization\\n2.1 Mathematical Principles of Generative AIGenerative AI is primarily based on generative modeling,\\nwhich has distinctive mathematical differences from dis-\\ncriminative modeling (Ng and Jordan 2001 ) often used in\\ndata-driven decision support. In general, discriminativemodeling tries to separate data points Xinto different\\nclasses Yby learning decision boundaries between them\\n(e.g., in classiﬁcation tasks with Y2f0;1g). In contrast to\\nthat, generative modeling aims to infer some actual data\\ndistribution. Examples can be the joint probability distri-\\nbution P(X,Y) of both the inputs and the outputs or P(Y),\\nbut where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to',\n 'bution P(X,Y) of both the inputs and the outputs or P(Y),\\nbut where Yis typically from some high-dimensional\\nspace. By doing so, a generative model offers the ability to\\nproduce new synthetic samples (e.g., generate new obser-vation-target-pairs ( X,Y) or new observations Xgiven a\\ntarget value Y) (Bishop 2006 ).\\nBuilding upon the above, a generative AI model refers to\\ngenerative modeling that is instantiated with a machine\\nlearning architecture (e.g., a deep neural network) and,\\ntherefore, can create new data samples based on learnedpatterns.\\n1Further, a generative AI system encompasses the\\nentire infrastructure, including the model, data processing,\\nand user interface components. The model serves as thecore component of the system, which facilitates interaction',\n 'entire infrastructure, including the model, data processing,\\nand user interface components. The model serves as thecore component of the system, which facilitates interaction\\nand application within a broader context. Lastly, generative\\nAI applications refer to the practical use cases and imple-\\nmentations of these systems, such as search engine opti-\\nmization (SEO) content generation or code generation that\\nsolve real-world problems and drive innovation acrossvarious domains. Figure 1shows a systematization of\\ngenerative AI across selected data modalities (e.g., text,\\nimage, and audio) and the model-, system-, and application-level perspectives, which we detail in the following section.Note that the modalities in Fig. 1are neither complete',\n 'image, and audio) and the model-, system-, and application-level perspectives, which we detail in the following section.Note that the modalities in Fig. 1are neither complete\\nnor entirely distinctive and can be detailed further. In\\naddition, many unique use cases such as, for example,\\nmodeling functional properties of proteins (Unsal et al.2022 ) can be represented in another modality such as text.\\n2.2 A Model-, System-, and Application-Level View\\nof Generative AI\\n2.2.1 Model-Level ViewA generative AI model is a type of machine learning\\narchitecture that uses AI algorithms to create novel data\\ninstances, drawing upon the patterns and relationships\\nobserved in the training data. A generative AI model is ofcritically central yet incomplete nature, as it requires fur-',\n 'instances, drawing upon the patterns and relationships\\nobserved in the training data. A generative AI model is ofcritically central yet incomplete nature, as it requires fur-\\nther ﬁne-tuning to speciﬁc tasks through systems and\\napplications.\\nDeep neural networks are particularly well suited for the\\npurpose of data generation, especially as deep neural net-\\nworks can be designed using different architectures tomodel different data types (Janiesch et al. 2021 ; Kraus\\net al. 2020 ), for example, sequential data such as human\\nlanguage or spatial data such as images. Table 1presents\\nan overview of the underlying concepts and model archi-\\ntectures that are common in the context of generative AI,',\n 'language or spatial data such as images. Table 1presents\\nan overview of the underlying concepts and model archi-\\ntectures that are common in the context of generative AI,\\nsuch as diffusion probabilistic models for text-to-imagegeneration or the transformer architecture and (large) lan-\\nguage models (LLMs) for text generation. GPT (short for\\ngenerative pre-trained transformer), for example, repre-sents a popular family of LLMs, used for text generation,\\nfor instance, in the conversational agent ChatGPT.\\nLarge generative AI models that can model output in\\nand across speciﬁc domains or speciﬁc data types in a\\ncomprehensive and versatile manner are oftentimes also\\ncalled foundation models (Bommasani et al. 2021 ). Due to\\ntheir size, they exhibit two key properties: emergence ,',\n 'comprehensive and versatile manner are oftentimes also\\ncalled foundation models (Bommasani et al. 2021 ). Due to\\ntheir size, they exhibit two key properties: emergence ,\\nmeaning the behavior is oftentimes implicitly induced\\nrather than explicitly constructed (e.g., GPT models cancreate calendar entries in the .ical format even though such\\nmodels were not explicitly trained to do so), and homog-\\nenization , where a wide range of systems and applications\\ncan now be powered by a single, consolidated model (e.g.,\\nCopilot can generate source code across a wide range of\\nprogramming languages).\\nFigure 1presents an overview of generative AI models\\nalong different, selected data modalities, which are pre-',\n 'Copilot can generate source code across a wide range of\\nprogramming languages).\\nFigure 1presents an overview of generative AI models\\nalong different, selected data modalities, which are pre-\\ntrained on massive amounts of data. Note that we structurethe models in Fig. 1by their output modality such as X-to-\\ntext or X-to-image. For example, GPT-4 as the most recent\\ngenerative AI model underlying OpenAI’s popular con-versational agent ChatGPT (OpenAI 2023a ) accepts both\\nimage and text inputs to generate text outputs. Similarly,\\n1It should be noted, however, that advanced generative AI models\\nare often not based on a single modeling principle or learningmechanism, but combine different approaches. For example, language\\nmodels from the GPT family ﬁrst apply a generative pre-training',\n 'are often not based on a single modeling principle or learningmechanism, but combine different approaches. For example, language\\nmodels from the GPT family ﬁrst apply a generative pre-training\\nstage to capture the distribution of language data using a languagemodeling objective, while downstream systems typically then apply adiscriminative ﬁne-tuning stage to adapt the model parameters to\\nspeciﬁc tasks (e.g., document classiﬁcation, question answering).\\nSimilarly, ChatGPT combines techniques from generative modelingtogether with discriminatory modeling and reinforcement learning(see Fig. 2).\\n123112 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)',\n '123112 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Midjourney accepts both modalities to generate images. To\\nthis end, generative AI models can also be grouped intounimodal and multimodal models. Unimodal models take\\ninstructions from the same input type as their output (e.g.,\\ntext). On the other hand, multimodal models can take inputfrom different sources and generate output in various\\nforms. Multimodal models exist across a variety of data\\nmodalities, for example for text, image, and audio.Prominent examples include Stable Diffusion (Rombach\\net al. 2022 ) for text-to-image generation, MusicLM\\n(Agostinelli et al. 2023 ) for text-to-music generation,',\n 'et al. 2022 ) for text-to-image generation, MusicLM\\n(Agostinelli et al. 2023 ) for text-to-music generation,\\nCodex (Chen et al. 2021 ) and AlphaCode (Li et al. 2022 )\\nfor text-to-code generation, and as mentioned above GPT-4\\nfor image-to-text as well as text-to-text generation(OpenAI 2023a ).\\nThe underlying training procedures vary greatly across\\ndifferent generative AI models (see Fig. 2). For example,\\ngenerative adversarial networks (GANs) are trained\\nthrough two competing objectives (Goodfellow et al.\\n2014 ), where one is to create new synthetic samples while\\nthe other tries to detect synthetic samples from the actual\\ntraining samples, so that the distribution of synthetic\\nsamples is eventually close to the distribution of thetraining samples. Differently, systems such as ChatGPT-',\n 'training samples, so that the distribution of synthetic\\nsamples is eventually close to the distribution of thetraining samples. Differently, systems such as ChatGPT-\\nbased conversational models use reinforcement learning\\nfrom human feedback (RLHF). RLHF as used by ChatGPT\\nproceeds in three steps to ﬁrst create demonstration data for\\nprompts, then to have users rank the quality of differentoutputs for a prompt, and ﬁnally to learn a policy that\\ngenerates desirable output via reinforcement learning so\\nthat the output would score well during ranking (Ziegleret al. 2019 ).2.2.2 System-Level View\\nAny system consists of a number of elements that are\\ninterconnected and interact with each other. For generativeAI systems, this comprises not only the aforementioned',\n 'Any system consists of a number of elements that are\\ninterconnected and interact with each other. For generativeAI systems, this comprises not only the aforementioned\\ngenerative AI model but also the underlying infrastructure,\\nuser-facing components, and their modality as well as thecorresponding data processing (e.g., for prompts). An\\nexample would be the integration of deep learning models,\\nlike Codex (Chen et al. 2021 ), into a more interactive and\\ncomprehensive system, like GitHub Copilot, which allows\\nits users to code more efﬁciently. Similarly, Midjourney’s\\nimage generation system builds on an undisclosed X-to-image generation model that users can interact with to\\ngenerate images using Discord bots. Thus, generative AI\\nsystems embed the functionality of the underlying mathe-',\n 'generate images using Discord bots. Thus, generative AI\\nsystems embed the functionality of the underlying mathe-\\nmatical model to provide an interface for user interaction.\\nThis step augments the model-speciﬁc capabilities,enhancing its practicability and usability across real-world\\nuse cases.\\nCore concerns when embedding deep learning models in\\ngenerative AI systems generally are scalability (e.g., dis-\\ntributed computing resources), deployment (e.g., in various\\nenvironments and for different devices), and usability (e.g.,a user-friendly interface and intent recognition). As pre-\\ntrained open-source alternatives to closed-source, propri-\\netary models continue to be released, making these modelsavailable to their users (be it companies or individuals)',\n 'trained open-source alternatives to closed-source, propri-\\netary models continue to be released, making these modelsavailable to their users (be it companies or individuals)\\nbecomes increasingly important. For both open-source and\\nclosed-source models, unexpected deterioration of modelperformance over time highlights the need for continuous\\nmodel monitoring (Chen et al. 2023 ). Although powerful\\ntext-generating models existed before the release of theFig. 1 A model-, system-, and\\napplication-level view ongenerative AI\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 113\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.Table 1 Glossary of key concepts in generative AI\\nConcept Description',\n 'Content courtesy of Springer Nature, terms of use apply. Rights reserved.Table 1 Glossary of key concepts in generative AI\\nConcept Description\\nDiffusion probabilistic models Diffusion probability models are a class of latent variable models that are common for various tasks such as\\nimage generation (Ho et al. 2020 ). Formally, diffusion probability models capture the image data by\\nmodeling the way data points diffuse through a latent space, which is inspired by statistical physics.\\nSpeciﬁcally, they typically use Markov chains trained with variational inference and then reverse the\\ndiffusion process to generate a natural image. A notable variant is Stable Diffusion (Rombach et al. 2022 ).\\nDiffusion probability models are also used in commercial systems such as DALL-E and Midjourney.',\n 'Diffusion probability models are also used in commercial systems such as DALL-E and Midjourney.\\nGenerative adversarial network A GAN is a class of neural network architecture with a custom, adversarial learning objective (Goodfellow\\net al. 2014 ). A GAN consists of two neural networks that contest with each other in the form of a zero-sum\\ngame, so that samples from a speciﬁc distribution can be generated. Formally, the ﬁrst network Gis called\\nthe generator, which generates candidate samples. The second network Dis called the discriminator, which\\nevaluates how likely the candidate samples come from a desired distribution. Thanks to the adversarial\\nlearning objective, the generator learns to map from a latent space to a data distribution of interest, while',\n 'learning objective, the generator learns to map from a latent space to a data distribution of interest, while\\nthe discriminator distinguishes candidates produced by the generator from the true data distribution (seeFig. 2).\\n(Large) language model A (large) language model (LLM) refers to neural networks for modeling and generating text data that\\ntypically combine three characteristics. First, the language model uses a large-scale, sequential neural\\nnetwork (e.g., transformer with an attention mechanism). Second, the neural network is pre-trained through\\nself-supervision in which auxiliary tasks are designed to learn a representation of natural language withoutrisk of overﬁtting (e.g., next-word prediction). Third, the pre-training makes use of large-scale datasets of',\n 'text (e.g., Wikipedia, or even multi-language datasets). Eventually, the language model may be ﬁne-tuned\\nby practitioners with custom datasets for speciﬁc tasks (e.g., question answering, natural languagegeneration). Recently, language models have evolved into so-called LLMs, which combine billions ofparameters. Prominent examples of massive LLMs are BERT (Devlin et al. 2018 ) and GPT-3 (Brown et al.\\n2020 ) with /C24340 million and /C24175 billion parameters, respectively.\\nReinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional',\n 'Reinforcement learning from\\nhuman feedbackRLHF learns sequential tasks (e.g., chat dialogues) from human feedback. Different from traditional\\nreinforcement learning, RLHF directly trains a so-called reward model from human feedback and then usesthe model as a reward function to optimize the policy, which is optimized through data-efﬁcient and robustalgorithms (Ziegler et al. 2019 ). RLHF is used in conversational systems such as ChatGPT (OpenAI 2022 )\\nfor generating chat messages, such that new answers accommodate the previous chat dialogue and ensure\\nthat the answers are in alignment with predeﬁned human preferences (e.g., length, style, appropriateness)\\nPrompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream',\n 'Prompt learning Prompt learning is a method for LLMs that uses the knowledge stored in language models for downstream\\ntasks (Liu et al. 2023 ). In general, prompt learning does not require any ﬁne-tuning of the language model,\\nwhich makes it efﬁcient and ﬂexible. A prompt is a speciﬁc input to a language model (e.g., ‘‘The movie\\nwas superb. Sentiment: ‘‘) and then the most probable output s2f‘‘positive’’ ;‘‘negative’’ ginstead of the\\nspace is picked. Recent advances allow for more complex data-driven prompt engineering, such as tuningprompts via reinforcement learning (Liu et al. 2023 ).\\nseq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is',\n 'seq2seq The term sequence-to-sequence (seq2seq) refers to machine learning approaches where an input sequence is\\nmapped onto an output sequence (Sutskever et al. 2014 ). An example is machine learning-based translation\\nbetween different languages. Such seq2seq approaches consist of two main components: An encoder turnseach element in a sequence (e.g., each word in a text) into a corresponding hidden vector containing the\\nelement and its context. The decoder reverses the process, turning the vector into an output element (e.g., a\\nword from the new language) while considering the previous output to model dependencies in language.The idea of seq2seq models has been extended to allow for multi-modal mappings such as text-to-image ortext-to-speech mappings.',\n 'Transformer A transformer is a deep learning architecture (Vaswani et al. 2017 ) that adopts the mechanism of self-\\nattention which differentially weights the importance of each part of the input data. Like recurrent neural\\nnetworks (RNNs), transformers are designed to process sequential input data, such as natural language, withapplications for tasks such as translation and text summarization. However, unlike RNNs, transformers\\nprocess the entire input all at once. The attention mechanism provides context for any position in the input',\n 'process the entire input all at once. The attention mechanism provides context for any position in the input\\nsequence. Eventually, the output of a transformer (or an RNN in general) is a document embedding, whichpresents a lower-dimensional representation of text (or other input) sequences where similar texts arelocated in closer proximity which typically beneﬁts downstream tasks as this allows to capture semantics\\nand meaning (Siebers et al. 2022 ).\\nVariational autoencoder A variational autoencoder (VAE) is a type of neural network that is trained to learn a low-dimensional',\n 'and meaning (Siebers et al. 2022 ).\\nVariational autoencoder A variational autoencoder (VAE) is a type of neural network that is trained to learn a low-dimensional\\nrepresentation of the input data by encoding it into a compressed latent variable space and thenreconstructing the original data from this compressed representation. VAEs differ from traditionalautoencoders by using a probabilistic approach to the encoding and decoding process, which enables them\\nto capture the underlying structure and variation in the data and generate new data samples from the learned\\nlatent space (Kingma and Welling 2013 ). This makes them useful for tasks such as anomaly detection and\\ndata compression but also image and text generation.',\n 'latent space (Kingma and Welling 2013 ). This makes them useful for tasks such as anomaly detection and\\ndata compression but also image and text generation.\\n123114 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.ChatGPT system in November 2022, ChatGPT’s ease of\\nuse also for non-expert users was a core contributing factor\\nto its explosive worldwide adoption.\\nMoreover, on the system level, multiple components of\\na generative AI system can be integrated or connected to\\nother systems, external databases with domain-speciﬁc\\nknowledge, or platforms. For example, common limitationsin many generative AI models are that they were trained on\\nhistorical data with speciﬁc cut-off date and thus do not',\n 'knowledge, or platforms. For example, common limitationsin many generative AI models are that they were trained on\\nhistorical data with speciﬁc cut-off date and thus do not\\nstore information beyond or that an information compres-sion takes place because of which generative AI models\\nmay not remember everything that they saw during training\\n(Chiang 2023 ). Both limitations can be mitigated by aug-\\nmenting the model with functionality for real-timeTable 1 continued\\nConcept Description\\nZero-shot learning / few-shot\\nlearningZero-shot learning and few-shot learning refer to different paradigms of how machine learning deals with\\nthe problem of data scarcity. Zero-shot learning is when a machine is taught how to learn a task from data',\n 'the problem of data scarcity. Zero-shot learning is when a machine is taught how to learn a task from data\\nwithout ever needing to access the data itself, while few-short learning refers to when there are only a fewspeciﬁc examples. Zero-shot learning and few-shot learning are often desirable in practice as they reducethe cost of setting up AI systems. LLMs are few-shot or zero-shot learners (Brown et al. 2020 ) as they just\\nneed a few samples to learn a task (e.g., predicting the sentiment of reviews), which makes LLMs highly\\nﬂexible as a general-purpose tool.\\nFig. 2 Examples of different training procedures for generative AI models. aGenerative adversarial network (GAN). bReinforcement learning\\nfrom human feedback (RLHF) as used in conversational generative AI models',\n 'from human feedback (RLHF) as used in conversational generative AI models\\n123S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024) 115\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.information retrieval, which can substantially enhance its\\naccuracy and usefulness. Relatedly, in the context of text\\ngeneration, online language modeling addresses the prob-\\nlem of outdated models by continuously training them onup-to-date data.\\n2Thereby, such models can then be\\nknowledgeable of recent events that their static counter-\\nparts would not be aware of due to their training cut-offdates.\\n2.2.3 Application-Level ViewGenerative AI applications are generative AI systems sit-\\nuated in organizations to deliver value by solving dedicated',\n '2.2.3 Application-Level ViewGenerative AI applications are generative AI systems sit-\\nuated in organizations to deliver value by solving dedicated\\nbusiness problems and addressing stakeholder needs. They\\ncan be regarded as human-task-technology systems orinformation systems that use generative AI technology to\\naugment human capacities to accomplish speciﬁc tasks.\\nThis level of generative AI encompasses countless real-world use cases: These range from SEO content generation\\n(Reisenbichler et al. 2022 ), over synthetic movie genera-\\ntion (Metz 2023 ) and AI music generation (Garcia 2023 ),\\nto natural language-based software development (Chen\\net al. 2021 ).\\nGenerative AI applications will give rise to novel\\ntechnology-enabled modes of work. The more users will',\n 'to natural language-based software development (Chen\\net al. 2021 ).\\nGenerative AI applications will give rise to novel\\ntechnology-enabled modes of work. The more users will\\nfamiliarize themselves with these novel applications, the\\nmore they will trust or mistrust them as well as use ordisuse them. Over time, applications will likely transition\\nfrom mundane tasks such as writing standard letters and\\ngetting a dinner reservation to more sensitive tasks such assoliciting medical or legal advice. They will involve more\\nconsequential decisions, which may even involve moral\\njudgment (Kru ¨gel et al. 2023 ). This ever-increasing scope\\nand pervasiveness of generative AI applications give rise to\\nan imminent need not only to provide prescriptions and',\n 'judgment (Kru ¨gel et al. 2023 ). This ever-increasing scope\\nand pervasiveness of generative AI applications give rise to\\nan imminent need not only to provide prescriptions and\\nprinciples for trustworthy and reliable designs, but also forscrutinizing the effects on the user to calibrate qualities\\nsuch as trust appropriately. The (continued) use and\\nadoption of such applications by end users and organiza-tions entails a number of fundamental socio-technical\\nconsiderations to descry innovation potential and affor-\\ndances of generative AI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what\\nconstitutes AI are continuously reﬁned, while the reference',\n 'dances of generative AI artifacts.\\n2.3 A Socio-Technical View on Generative AI\\nAs technology advances, the deﬁnition and extent of what\\nconstitutes AI are continuously reﬁned, while the reference\\npoint of human intelligence stays comparatively constant(Berente et al. 2021 ). With generative AI, we are\\napproaching a further point of reﬁnement . In the past, the\\ncapability of AI was mostly understood to be analytic,\\nsuitable for decision-making tasks. Now, AI gains thecapability to perform generative tasks, suitable for content\\ncreation. While the procedure of content creation to some\\nrespect can still be considered analytic as it is inherentlyprobabilistic, its results can be creative or even artistic as\\ngenerative AI combines elements in novel ways. Further,',\n 'respect can still be considered analytic as it is inherentlyprobabilistic, its results can be creative or even artistic as\\ngenerative AI combines elements in novel ways. Further,\\nIT artifacts were considered passive as they were used\\ndirectly by humans. With the advent of agentic IT artifacts\\n(Baird and Maruping 2021 ) powered by LLMs (Park et al.\\n2023 ), this human agency primacy assumption needs to be\\nrevisited and impacts how we devise the relation between\\nhuman and AI based on their potency. Eventually, this mayrequire AI capability models to structure, explain, guide,\\nand constrain the different abilities of AI systems and their\\nuses as AI applications.\\nFocusing on the interaction between humans and AI, so\\nfar, for analytic AI, the concept of delegation has been',\n 'and constrain the different abilities of AI systems and their\\nuses as AI applications.\\nFocusing on the interaction between humans and AI, so\\nfar, for analytic AI, the concept of delegation has been\\ndiscussed to establish a hierarchy for decision-making(Baird and Maruping 2021 ). With generative AI, a human\\nuses prompts to engage with an AI system to create con-\\ntent, and the AI then interprets the human’s intentions andprovides feedback to presuppose further prompts. At ﬁrst\\nglance, this seems to follow a delegation pattern as well.\\nYet, the subsequent process does not, as the output of theAI can be suggestive to the other and will inform their\\nfurther involvement directly or subconsciously. Thus, the',\n 'Yet, the subsequent process does not, as the output of theAI can be suggestive to the other and will inform their\\nfurther involvement directly or subconsciously. Thus, the\\nprocess of creation rather follows a co-creation pattern, thatis, the practice of collaborating in different roles to align\\nand offer diverse insights to guide a design process\\n(Ramaswamy and Ozcan 2018 ). Using the lens of agentic\\nAI artifacts, initiation is not limited to humans.\\nThe abovementioned interactions also impact our cur-\\nrent understanding of hybrid intelligence as the integrationof humans and AI, leveraging the unique strengths of both.\\nHybrid intelligence argues to address the limitations of\\neach intelligence type by combining human intuition, cre-ativity, and empathy with the computational power, accu-',\n 'Hybrid intelligence argues to address the limitations of\\neach intelligence type by combining human intuition, cre-ativity, and empathy with the computational power, accu-\\nracy, and scalability of AI systems to achieve enhanced\\ndecision-making and problem-solving capabilities (Deller-mann et al. 2019 ). With generative AI and the AI’s capa-\\nbility to co-create, the understanding of what constitutes\\nthis collective intelligence begins to shift. Hence, novelhuman-AI interaction models and patterns may become\\nnecessary to explain and guide the behavior of humans and\\nAI systems to enable effective and efﬁcient use in AIapplications on the one hand and, on the other hand, to\\nensure envelopment of AI agency and reach (Asatiani et al.\\n2021 ).\\nOn a theoretical level, this shift in human-computer or',\n 'ensure envelopment of AI agency and reach (Asatiani et al.\\n2021 ).\\nOn a theoretical level, this shift in human-computer or\\nrather human-AI interaction fuels another important2Seehttps://github.com/huggingface/olm-datasets (accessed 25 Aug\\n2023) for a script that enables users to pull up-to-date data from theweb for training online language models, for instance, from CommonCrawl and Wikipedia.\\n123116 S. Feuerriegel et al.: Generative AI, Bus Inf Syst Eng 66(1):111–126 (2024)\\nContent courtesy of Springer Nature, terms of use apply. Rights reserved.observation: The theory of mind is an established theoret-\\nical lens in psychology to describe the cognitive ability of\\nindividuals to understand and predict the mental states,\\nemotions, and intentions of others (Carlson et al. 2013 ;',\n 'ical lens in psychology to describe the cognitive ability of\\nindividuals to understand and predict the mental states,\\nemotions, and intentions of others (Carlson et al. 2013 ;\\nBaron-Cohen 1997 ; Gray et al. 2007 ). This skill is crucial\\nfor social interactions, as it facilitates empathy and allows\\nfor effective communication. Moreover, conferring a mindto an AI system can substantially drive usage intensity\\n(Hartmann et al. 2023a ). The development of a theory of\\nmind in humans is unconscious and evolves throughout an\\nindividual’s life. The more natural AI systems become in\\nterms of their interface and output, the more a theory ofmind for human-computer interactions becomes necessary.\\nResearch is already investigating how AI systems can',\n 'terms of their interface and output, the more a theory ofmind for human-computer interactions becomes necessary.\\nResearch is already investigating how AI systems can\\nbecome theory-of-mind-aware to better understand theirhuman counterpart (Rabinowitz et al. 2018 ;C¸ elikok et al.\\n2019 ). However, current AI systems hardly offer any cues\\nfor interactions. Thus, humans are rather void of a theory toexplain their understanding of intelligent behavior by AI\\nsystems, which becomes even more important in a co-\\ncreation environment that does not follow a task delegationpattern. A theory of the artiﬁcial mind that explains how\\nindividuals perceive and assume the states and rationale of\\nAI systems to better collaborate with them may alleviatesome of these concerns.',\n 'individuals perceive and assume the states and rationale of\\nAI systems to better collaborate with them may alleviatesome of these concerns.\\n3 Limitations of Current Generative AI\\nIn the following, we discuss four salient boundaries of\\ngenerative AI that, we argue, are important limitations in\\nreal-world applications. The following limitations are of\\ntechnical nature in that they refer to how current generativeAI models make inferences, and, hence, the limitations\\narise at the model level. Because of this, it is likely that\\nlimitations will persist in the long run, with system- andapplication-level implications.\\nIncorrect outputs. Generative AI models may produce\\noutput with errors. This is owed to the underlying nature ofmachine learning models relying on probabilistic algo-',\n 'Incorrect outputs. Generative AI models may produce\\noutput with errors. This is owed to the underlying nature ofmachine learning models relying on probabilistic algo-\\nrithms for making inferences. For example, generative AI\\nmodels generate the most probable response to a prompt,not necessarily the correct response. As such, challenges\\narise as, by now, outputs are indistinguishable from\\nauthentic content and may present misinformation ordeceive users (Spitale et al. 2023 ). In LLMs, this problem\\nin emergent behavior is called hallucination (Ji et al. 2023 ),\\nwhich refers to mistakes in the generated text that aresemantically or syntactically plausible but are actually\\nnonsensical or incorrect. In other words, the generative AI',\n 'which refers to mistakes in the generated text that aresemantically or syntactically plausible but are actually\\nnonsensical or incorrect. In other words, the generative AI\\nmodel produces content that is not based on any facts orevidence, but rather on its own assumptions or biases.Moreover, the output of generative AI, especially that of\\nLLMs, is typically not easily veriﬁable.\\nThe correctness of generative AI models is highly\\ndependent on the quality of training data and the accordinglearning process. Generative AI systems and applications\\ncan implement correctness checks to inhibit certain out-\\nputs. Yet, due to the black-box nature of state-of-the-art AImodels (Rai 2020 ), the usage of such systems critically\\nhinges on users’ trust in reliable outputs. The closed source',\n 'puts. Yet, due to the black-box nature of state-of-the-art AImodels (Rai 2020 ), the usage of such systems critically\\nhinges on users’ trust in reliable outputs. The closed source\\nof commercial off-the-shelf generative AI systems aggra-\\nvates this fact and prohibits further tuning and re-training\\nof the models. One solution for addressing the downstreamimplications of incorrect outputs is to use generative AI to\\nproduce explanations or references, which can then be\\nveriﬁed by users. However, such explanations are againprobabilistic and thus subject to errors; nevertheless, they\\nmay help users in their judgment and decision-making\\nwhen to accept outputs of generative AI and when not.\\nBias and fairness. Societal biases permeate everyday\\nhuman-generated content (Eskreis-Winkler and Fishbach']"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629ae82-d81c-4d16-b4fb-af517ff78fdd",
   "metadata": {},
   "source": [
    "### Load the dataset into the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7bf12245-b868-43a5-bb0a-b1e9fe506bc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:28:46.342418Z",
     "start_time": "2024-04-26T14:28:41.379240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 150 headlines.\n"
     ]
    }
   ],
   "source": [
    "astra_vector_store.add_texts(texts)\n",
    "print(\"Inserted %i headlines.\" % len(texts))\n",
    "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0facd7b-6868-4fce-bdf8-4ba707391f2c",
   "metadata": {},
   "source": [
    "### Run the Q/A cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4f073095-dc07-4a5b-bbaf-84dd6218c891",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T14:29:27.263958Z",
     "start_time": "2024-04-26T14:28:50.066228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: \"What are the concerns when embedding deep learning models in generative AI?\"\n",
      "ANSWER: \"Concerns include the need for guidelines and governance frameworks, verifying model outputs, relying appropriately on generative AI systems, and addressing bias and fairness issues.\"\n",
      "\n",
      "FIRST DOCUMENTS BY RELEVANCE:\n",
      "    [0.9325] \"material such as teaching cases and recap questions. Fur-\n",
      "ther, the educator’s commu ...\"\n",
      "    [0.9324] \"material such as teaching cases and recap questions. Fur-\n",
      "ther, the educator’s commu ...\"\n",
      "    [0.9319] \"when to accept outputs of generative AI and when not.\n",
      "Bias and fairness. Societal bi ...\"\n",
      "    [0.9319] \"when to accept outputs of generative AI and when not.\n",
      "Bias and fairness. Societal bi ...\"\n"
     ]
    }
   ],
   "source": [
    "first_question = True\n",
    "while True:\n",
    "    if first_question:\n",
    "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
    "    else:\n",
    "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
    "\n",
    "    if query_text.lower() == \"quit\":\n",
    "        break\n",
    "\n",
    "    if query_text == \"\":\n",
    "        continue\n",
    "\n",
    "    first_question = False\n",
    "\n",
    "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
    "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
    "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
    "\n",
    "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
    "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
    "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
